[{"id":"a4cffafc-3ff0-4cd2-8bfc-7ab7b87fb1fd","userId":"42367af0-87b8-4355-8971-694de25bc23c","tool":{"id":"run_code","name":"Run code","meta":{"description":"Run arbitrary Python or Bash code safely in a gVisor sandbox.","manifest":{"id":"run_code","title":"Run code","description":"Run arbitrary Python or Bash code safely in a gVisor sandbox.","author":"EtiennePerot","author_url":"https://github.com/EtiennePerot/safe-code-execution","funding_url":"https://github.com/EtiennePerot/safe-code-execution","version":"0.8.0","license":"Apache-2.0"}},"content":"\"\"\"\nid: run_code\ntitle: Run code\ndescription: Run arbitrary Python or Bash code safely in a gVisor sandbox.\nauthor: EtiennePerot\nauthor_url: https://github.com/EtiennePerot/safe-code-execution\nfunding_url: https://github.com/EtiennePerot/safe-code-execution\nversion: 0.8.0\nlicense: Apache-2.0\n\"\"\"\n\n\n# NOTE: If running Open WebUI in a container, you *need* to set up this container to allow sandboxed code execution.\n# Please read the docs here:\n#\n#   https://github.com/EtiennePerot/safe-code-execution/blob/master/README.md\n#\n# This is an OpenWebUI *tool*. It allows an LLM to generate and call code on its own.\n# If you are looking for an OpenWebUI *function* to allow you to manually execute blocks\n# of code in the LLM output, see here instead:\n# https://openwebui.com/f/etienneperot/run_code/\n\n#\n# See https://github.com/EtiennePerot/safe-code-execution for more info.\n#\n# Protip: You can test this manually by running it as a Python script, like so:\n# (Run this inside the Open WebUI container)\n#\n#   python3 run_code.py --self_test\n#\n# This will simulate that OpenWebUI would do if it asked this tool to evaluate the Python code `print(\"Hello world!\")`.\n# This can be useful when setting up this tool to verify that it works in your environment.\n# You can also use it for one-off code execution like this:\n#\n#   echo 'print(\"Hello world!\")' | python3 run_code.py\n#\n\nimport asyncio\nimport argparse\nimport json\nimport os\nimport os.path\nimport pydantic\nimport subprocess\nimport sys\nimport tempfile\nimport typing\nimport inspect\nimport base64\nimport ctypes\nimport ctypes.util\nimport copy\nimport hashlib\nimport platform\nimport re\nimport shutil\nimport signal\nimport threading\nimport time\nimport urllib.request\nimport datetime\nimport urllib.error\n\n\nclass _Tools:\n    class Valves(pydantic.BaseModel):\n        _VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX = \"CODE_EVAL_VALVE_OVERRIDE_\"\n        NETWORKING_ALLOWED: bool = pydantic.Field(\n            default=True,\n            description=f\"Whether to allow network access during code execution; may be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}NETWORKING_ALLOWED.\",\n        )\n        MAX_RUNTIME_SECONDS: int = pydantic.Field(\n            ge=1,\n            default=30,\n            description=f\"Maximum number of seconds code is given to run; may be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}MAX_RUNTIME_SECONDS.\",\n        )\n        MAX_RAM_MEGABYTES: int = pydantic.Field(\n            ge=0,\n            default=128,\n            description=f\"Maximum number of megabytes that the interpreter has when running. Must run as root with host cgroups writable (`--mount=type=bind,source=/sys/fs/cgroup,target=/sys/fs/cgroup,readonly=false`) for this to work. Set to 0 to disable memory limits. May be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}MAX_RAM_MEGABYTES\",\n        )\n        REQUIRE_RESOURCE_LIMITING: bool = pydantic.Field(\n            default=True,\n            description=f\"Whether to enforce resource limiting, which requires cgroups v2 to be available; may be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}REQUIRE_RESOURCE_LIMITING.\",\n        )\n        AUTO_INSTALL: bool = pydantic.Field(\n            default=True,\n            description=f\"Whether to automatically install gVisor if not installed on the system; may be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}AUTO_INSTALL. Use the 'HTTPS_PROXY' environment variable to control the proxy used for download.\",\n        )\n        CHECK_FOR_UPDATES: bool = pydantic.Field(\n            default=True,\n            description=f\"Whether to automatically check for updates; may be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}CHECK_FOR_UPDATES. Use the 'HTTPS_PROXY' environment variable to control the proxy used for update checks.\",\n        )\n        DEBUG: bool = pydantic.Field(\n            default=False,\n            description=f\"Whether to produce debug logs during execution; may be overridden by environment variable {_VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}DEBUG.\",\n        )\n\n    def __init__(self, valves):\n        self.valves = valves\n        for valve_name, valve_value in valves.dict().items():\n            override = os.getenv(\n                self.valves._VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX\n                + valve_name\n            )\n            if override is None:\n                continue\n            try:\n                if type(valve_value) is type(True):\n                    assert override.lower() in (\n                        \"true\",\n                        \"false\",\n                    ), 'Value must be \"true\" or \"false\"'\n                    override = override.lower() == \"true\"\n                elif type(valve_value) is type(42):\n                    override = int(override)\n                else:\n                    valve_value_type = type(valve_value)\n                    raise ValueError(f\"Unknown valve type: {valve_value_type}\")\n            except Exception as e:\n                raise ValueError(\n                    f\"Valve override {self.valves._VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX}{valve_name}={valve_value}: bad value: {e}\"\n                )\n            else:\n                setattr(self.valves, valve_name, override)\n\n    async def run_bash_command(\n        self,\n        bash_command: str,\n        __event_emitter__: typing.Callable[[dict], typing.Any] = None,\n    ) -> str:\n        \"\"\"\n        Run a bash command-line or script safely in a gVisor sandbox.\n\n        :param bash_command: Bash command or script to run.\n\n        :return: A JSON object with the following fields: `bash_command`, `status`, `output`. In most cases, when `status` is \"OK\", the user is interested in the content of the `output` field. Otherwise, report the `status` field first.\n        \"\"\"\n        result = await self._run_code(\n            language=Sandbox.LANGUAGE_BASH,\n            code=bash_command,\n            event_emitter=__event_emitter__,\n        )\n        return json.dumps(\n            {\n                \"bash_command\": bash_command,\n                \"status\": result[\"status\"],\n                \"output\": result[\"output\"],\n            },\n            ensure_ascii=False,\n        )\n\n    async def run_python_code(\n        self,\n        python_code: str,\n        __event_emitter__: typing.Callable[[dict], typing.Any] = None,\n    ) -> str:\n        \"\"\"\n        Run Python code safely in a gVisor sandbox.\n\n        :param python_code: Python code to run.\n\n        :return: A JSON object with the following fields: `python_code`, `status`, `output`. In most cases, when `status` is \"OK\", the user is interested in the content of the `output` field. Otherwise, report the `status` field first.\n        \"\"\"\n        result = await self._run_code(\n            language=Sandbox.LANGUAGE_PYTHON,\n            code=python_code,\n            event_emitter=__event_emitter__,\n        )\n        return json.dumps(\n            {\n                \"python_code\": python_code,\n                \"status\": result[\"status\"],\n                \"output\": result[\"output\"],\n            },\n            ensure_ascii=False,\n        )\n\n    async def _run_code(\n        self,\n        language: str,\n        code: str,\n        event_emitter: typing.Callable[[dict], typing.Any] = None,\n    ) -> str:\n        \"\"\"\n        Run code safely in a gVisor sandbox.\n\n        :param language: Programming language of the code.\n        :param code: The code to run.\n        :param event_emitter: Event emitter to send status updates to.\n\n        :return: A dictionary with the following fields: `status`, `output`.\n        \"\"\"\n        valves = self.valves\n        debug = valves.DEBUG\n        emitter = EventEmitter(event_emitter, debug=debug)\n\n        if valves.CHECK_FOR_UPDATES:\n            if UpdateCheck.need_check():\n                await emitter.status(\"Checking for updates...\")\n            try:\n                newer_version = UpdateCheck.get_newer_version()\n            except UpdateCheck.VersionCheckError as e:\n                emitter.set_status_prefix(f\"[Code execution update check failed: {e}] \")\n            else:\n                if newer_version is not None:\n                    await emitter.status(\n                        f\"Code execution: Update available: {newer_version}\"\n                    )\n                    emitter.set_status_prefix(\n                        f\"[Code execution update available: {newer_version}] \"\n                    )\n\n        async def _fail(error_message, status=\"SANDBOX_ERROR\"):\n            if debug:\n                await emitter.fail(\n                    f\"[DEBUG MODE] {error_message}; language={language}; code={code}; valves=[{valves}]\"\n                )\n            else:\n                await emitter.fail(error_message)\n            return {\"status\": status, \"output\": error_message}\n\n        try:\n            max_ram_bytes = None\n            if valves.MAX_RAM_MEGABYTES != 0:\n                max_ram_bytes = valves.MAX_RAM_MEGABYTES * 1024 * 1024\n\n            await emitter.status(\"Checking if environment supports sandboxing...\")\n            Sandbox.check_setup(\n                language=language,\n                auto_install_allowed=valves.AUTO_INSTALL,\n                require_resource_limiting=valves.REQUIRE_RESOURCE_LIMITING,\n            )\n\n            if valves.AUTO_INSTALL and Sandbox.runsc_needs_installation():\n                await emitter.status(\"Auto-installing gVisor...\")\n                Sandbox.install_runsc()\n\n            await emitter.status(\"Initializing sandbox configuration...\")\n            status = \"UNKNOWN\"\n            output = None\n            language_title = language.title()\n\n            # If the provided code starts/ends with \"```\" or\n            # \"```SOME_LANGUAGE\", remove that.\n            code = code.strip()\n            code = code.removeprefix(\"```\" + language)\n            code = code.removeprefix(\"```\")\n            code = code.removesuffix(\"```\")\n\n            # If the provided code is a single line enclosed in\n            # \"`\"s, strip those and whitespace away.\n            code = code.strip()\n            code = code.strip(\"`\")\n            code = code.strip()\n\n            with tempfile.TemporaryDirectory(prefix=\"sandbox_\") as tmp_dir:\n                sandbox = Sandbox(\n                    tmp_dir=tmp_dir,\n                    language=language,\n                    code=code,\n                    debug=debug,\n                    networking_allowed=valves.NETWORKING_ALLOWED,\n                    max_runtime_seconds=valves.MAX_RUNTIME_SECONDS,\n                    max_ram_bytes=max_ram_bytes,\n                    require_resource_limiting=valves.REQUIRE_RESOURCE_LIMITING,\n                    persistent_home_dir=None,\n                )\n\n                await emitter.status(\n                    f\"Running {language_title} code in gVisor sandbox...\"\n                )\n\n                await emitter.citation(\n                    document=[code], metadata=[code], source={\"name\": \"run_code\"}\n                )\n\n                try:\n                    result = sandbox.run()\n                except Sandbox.ExecutionTimeoutError as e:\n                    await emitter.fail(\n                        f\"Code timed out after {valves.MAX_RUNTIME_SECONDS} seconds\"\n                    )\n                    status = \"TIMEOUT\"\n                    output = e.stderr\n                except Sandbox.InterruptedExecutionError as e:\n                    await emitter.fail(\"Code used too many resources\")\n                    status = \"INTERRUPTED\"\n                    output = e.stderr\n                except Sandbox.CodeExecutionError as e:\n                    await emitter.fail(f\"{language_title}: {e}\")\n                    status = \"ERROR\"\n                    output = e.stderr\n                else:\n                    await emitter.status(\n                        status=\"complete\",\n                        done=True,\n                        description=f\"{language_title} code executed successfully.\",\n                    )\n                    status = \"OK\"\n                    output = result.stdout or result.stderr\n                if output:\n                    output = output.strip()\n                if debug:\n                    per_file_logs = {}\n\n                    def _log(filename: str, log_line: str):\n                        print(f\"[{filename}] {log_line}\", file=sys.stderr)\n                        if filename not in per_file_logs:\n                            per_file_logs[filename] = []\n                        per_file_logs[filename].append(log_line)\n\n                    sandbox.debug_logs(_log)\n                    await emitter.status(\n                        status=\"complete\" if status == \"OK\" else \"error\",\n                        done=True,\n                        description=f\"[DEBUG MODE] status={status}; output={output}; valves=[{valves}]; debug={per_file_logs}\",\n                    )\n            return {\n                \"status\": status,\n                \"output\": output,\n            }\n        except Sandbox.PlatformNotSupportedException as e:\n            return await _fail(f\"Sandbox cannot run on this machine: {e}\")\n        except Sandbox.SandboxRuntimeException as e:\n            return await _fail(f\"Sandbox runtime failed: {e}\")\n        except Sandbox.FixableException as e:\n            return await _fail(f\"Environment needs setup work: {e}\")\n        except Sandbox.SandboxException as e:\n            return await _fail(f\"Sandbox exception: {e}\")\n        except Exception as e:\n            return await _fail(f\"Unhandled exception: {e}\")\n\n\nclass Tools:\n    Valves = _Tools.Valves\n\n    def __init__(self):\n        self.valves = self.Valves()\n\n    async def run_bash_command(\n        self,\n        bash_command: str,\n        __event_emitter__: typing.Callable[[dict], typing.Any] = None,\n    ) -> str:\n        \"\"\"\n        Run a bash command-line or script safely in a gVisor sandbox.\n\n        :param bash_command: Bash command or script to run.\n\n        :return: A JSON object with the following fields: `status`, `output`. In most cases, when `status` is \"OK\", the user is interested in the content of the `output` field. Otherwise, report the `status` field first.\n        \"\"\"\n        return await _Tools(self.valves).run_bash_command(\n            bash_command=bash_command,\n            __event_emitter__=__event_emitter__,\n        )\n\n    async def run_python_code(\n        self,\n        python_code: str,\n        __event_emitter__: typing.Callable[[dict], typing.Any] = None,\n    ) -> str:\n        \"\"\"\n        Run Python code safely in a gVisor sandbox.\n\n        :param python_code: Python code to run.\n\n        :return: A JSON object with the following fields: `status`, `output`. In most cases, when `status` is \"OK\", the user is interested in the content of the `output` field. Otherwise, report the `status` field first.\n        \"\"\"\n        return await _Tools(self.valves).run_python_code(\n            python_code=python_code,\n            __event_emitter__=__event_emitter__,\n        )\n\n\nclass EventEmitter:\n    \"\"\"\n    Helper wrapper for OpenWebUI event emissions.\n    \"\"\"\n\n    def __init__(\n        self,\n        event_emitter: typing.Callable[[dict], typing.Any] = None,\n        debug: bool = False,\n    ):\n        self.event_emitter = event_emitter\n        self._debug = debug\n        self._status_prefix = None\n\n    def set_status_prefix(self, status_prefix):\n        self._status_prefix = status_prefix\n\n    async def _emit(self, typ, data):\n        if self._debug:\n            print(f\"Emitting {typ} event: {data}\", file=sys.stderr)\n        if not self.event_emitter:\n            return None\n        maybe_future = self.event_emitter(\n            {\n                \"type\": typ,\n                \"data\": data,\n            }\n        )\n        if asyncio.isfuture(maybe_future) or inspect.isawaitable(maybe_future):\n            return await maybe_future\n\n    async def status(\n        self, description=\"Unknown state\", status=\"in_progress\", done=False\n    ):\n        if self._status_prefix is not None:\n            description = f\"{self._status_prefix}{description}\"\n        await self._emit(\n            \"status\",\n            {\n                \"status\": status,\n                \"description\": description,\n                \"done\": done,\n            },\n        )\n        if not done and len(description) <= 1024:\n            # Emit it again; Open WebUI does not seem to flush this reliably.\n            # Only do it for relatively small statuses; when debug mode is enabled,\n            # this can take up a lot of space.\n            await self._emit(\n                \"status\",\n                {\n                    \"status\": status,\n                    \"description\": description,\n                    \"done\": done,\n                },\n            )\n\n    async def fail(self, description=\"Unknown error\"):\n        await self.status(description=description, status=\"error\", done=True)\n\n    async def message(self, content):\n        await self._emit(\n            \"message\",\n            {\n                \"content\": content,\n            },\n        )\n\n    async def citation(self, document, metadata, source):\n        await self._emit(\n            \"citation\",\n            {\n                \"document\": document,\n                \"metadata\": metadata,\n                \"source\": source,\n            },\n        )\n\n    async def code_execution_result(self, output):\n        await self._emit(\n            \"code_execution_result\",\n            {\n                \"output\": output,\n            },\n        )\n\n\nclass Sandbox:\n    \"\"\"\n    Sandbox manages a gVisor sandbox's lifecycle.\n    \"\"\"\n\n    # Set of supported programming languages.\n    LANGUAGE_PYTHON = \"python\"\n    LANGUAGE_BASH = \"bash\"\n    SUPPORTED_LANGUAGES = [LANGUAGE_PYTHON, LANGUAGE_BASH]\n\n    # The following directories will be exposed as read-only to the\n    # sandboxed environment. This must contain at least the necessary\n    # files and libraries necessary to run the code interpreter.\n    # Subdirectories of these directories may be hidden by adding them\n    # to the `EMPTY_READ_ONLY_DIRECTORIES` or `EMPTY_WRITABLE_DIRECTORIES`\n    # lists below.\n    EXPOSED_SYSTEM_DIRECTORIES = [\n        \"/bin\",\n        \"/etc/alternatives\",\n        \"/etc/ssl/certs\",\n        \"/lib\",\n        \"/lib32\",\n        \"/lib64\",\n        \"/opt\",\n        \"/sbin\",\n        \"/usr\",\n        \"/var/lib\",\n    ]\n\n    # The following files will be exposed as read-only to the sandboxed\n    # environment. This should contain the set of files necessary by the\n    # code interpreter to function correctly, e.g. `/etc/resolv.conf`\n    # is necessary to properly resolve hosts through DNS.\n    EXPOSED_SYSTEM_FILES = [\n        \"/etc/hosts\",\n        \"/etc/localtime\",\n        \"/etc/mime.types\",\n        \"/etc/nsswitch.conf\",\n        \"/etc/os-release\",\n        \"/etc/resolv.conf\",\n        \"/etc/shells\",\n    ]\n\n    # The following directories will exist in the sandbox environment but\n    # will appear as empty and read-only.\n    # This is useful to have a filesystem that feels like a normal Linux\n    # environment without actually revealing these directories to the\n    # sandbox.\n    EMPTY_READ_ONLY_DIRECTORIES = [\n        \"/etc\",\n        \"/home\",\n        \"/lost+found\",\n        \"/root\",\n        \"/run\",\n        \"/run/user\",\n        \"/sys\",\n        \"/var\",\n    ]\n\n    # The following directories will exist in the sandbox environment but\n    # will appear as empty and writable.\n    # This is useful to have a filesystem that feels like a normal Linux\n    # environment without actually revealing these directories to the\n    # sandbox.\n    EMPTY_WRITABLE_DIRECTORIES = [\n        \"/dev/shm\",\n        \"/home/user\",\n        \"/run/user/1000\",\n        \"/var/run\",\n        \"/var/tmp\",\n        \"/tmp\",\n    ]\n\n    # Static parts of the OCI configuration.\n    OCI_CONFIG_SKELETON = {\n        \"ociVersion\": \"1.0.0\",\n        \"process\": {\n            \"user\": {\"uid\": 1000, \"gid\": 1000},\n            \"args\": [\"/bin/INVALID\"],  # Will be filled in.\n            \"env\": [\n                # Basic environment variables.\n                \"EDITOR=cat\",\n                \"LANG=C.UTF-8\",\n                \"LC_ALL=C.UTF-8\",\n                \"LC_CTYPE=C.UTF-8\",\n                \"HOME=/home/user\",\n                \"HOSTNAME=sandbox\",\n                \"PAGER=cat\",\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"PWD=/home/user\",\n                \"SHLVL=1\",\n                \"TERM=xterm\",\n                \"USER=user\",\n                \"TZ=\" + time.tzname[0],\n            ],\n            \"cwd\": \"/home/user\",\n            \"capabilities\": {\n                # No capabilities whatsoever.\n                \"bounding\": [],\n                \"effective\": [],\n                \"inheritable\": [],\n                \"permitted\": [],\n            },\n            \"rlimits\": [\n                {\"type\": \"RLIMIT_NOFILE\", \"hard\": 1048576, \"soft\": 1048576},\n            ],\n            \"noNewPrivileges\": True,\n        },\n        \"root\": {\n            \"path\": \"/invalid\",  # Will be filled in.\n            \"readonly\": True,\n        },\n        \"hostname\": \"sandbox\",\n        \"mounts\": [\n            {\"destination\": \"/dev\", \"type\": \"dev\"},\n            {\"destination\": \"/proc\", \"type\": \"proc\"},\n        ],\n        \"linux\": {\n            \"namespaces\": [\n                {\"type\": \"pid\"},\n                {\"type\": \"ipc\"},\n                {\"type\": \"uts\"},\n                {\"type\": \"mount\"},\n            ],\n            \"resources\": {\n                \"memory\": {\n                    # `limit` may be be filled in here depending on user configuration.\n                    \"disableOOMKiller\": False,\n                },\n            },\n        },\n    }\n\n    # The path where the `runsc` binary will be downloaded and installed if\n    # requested.\n    AUTO_INSTALLATION_PATH = \"/tmp/gvisor/runsc\"\n\n    # Regular expression for log filename prefixes generated by `runsc`.\n    _LOG_FILENAME_TRUNCATE_RE = re.compile(r\"^runsc\\.log\\.\\d{8}-\\d{6}(?:\\.\\d+)?\\.\")\n\n    # Other files worth logging when dumping debug logs.\n    _EXTRA_DEBUG_LOG_PATHS = (\n        \"/etc/os-release\",\n        \"/proc/self/cgroup\",\n        \"/proc/self/personality\",\n        \"/proc/self/mountinfo\",\n        \"/proc/self/setgroups\",\n        \"/proc/self/status\",\n        \"/proc/self/uid_map\",\n        \"/proc/self/gid_map\",\n        \"/proc/cmdline\",\n        \"/proc/cpuinfo\",\n        \"/proc/cgroups\",\n        \"/proc/mounts\",\n        \"/proc/version\",\n    )\n\n    # Other commands worth running when dumping debug logs.\n    _EXTRA_DEBUG_LOG_COMMANDS = (\n        (\"pwd\",),\n        (\"id\",),\n        (\"uname\", \"-a\"),\n        (\"ls\", \"-l\", \"/proc/self/ns\"),\n        (\"findmnt\",),\n        (sys.executable, \"--version\"),\n    )\n\n    # Environment variable used to detect interpreter re-execution.\n    _MARKER_ENVIRONMENT_VARIABLE = \"__CODE_EXECUTION_STAGE\"\n\n    # libc bindings.\n    # Populated using `_libc`.\n    _LIBC = None\n\n    class _Libc:\n        \"\"\"\n        Wrapper over libc functions.\n        \"\"\"\n\n        def __init__(self):\n            libc = ctypes.CDLL(ctypes.util.find_library(\"c\"), use_errno=True)\n            libc.mount.argtypes = (ctypes.c_char_p,)\n            self._libc = libc\n\n        def mount(self, source, target, fs, options):\n            if (\n                self._libc.mount(\n                    source.encode(\"ascii\"),\n                    target.encode(\"ascii\"),\n                    fs.encode(\"ascii\"),\n                    0,\n                    options.encode(\"ascii\"),\n                )\n                < 0\n            ):\n                errno = ctypes.get_errno()\n                raise OSError(\n                    errno,\n                    f\"mount({source}, {target}, {fs}, {options}): {os.strerror(errno)}\",\n                )\n\n        def umount(self, path):\n            if self._libc.umount(path.encode(\"ascii\")) < 0:\n                errno = ctypes.get_errno()\n                raise OSError(errno, f\"umount({path}): {os.strerror(errno)}\")\n\n        def unshare(self, flags):\n            if self._libc.unshare(flags) < 0:\n                raise OSError(f\"unshare({flags}) failed\")\n\n    class _SelfFile:\n        \"\"\"\n        Manages a copy of this file's own contents.\n        \"\"\"\n\n        _CONTENTS = None\n\n        @classmethod\n        def init(cls):\n            \"\"\"\n            Read `__file__` into `cls._CONTENTS`. Must be called during init.\n            \"\"\"\n            if cls._CONTENTS is None:\n                with open(__file__, \"rb\") as self_f:\n                    cls._CONTENTS = self_f.read().decode(\"ascii\")\n\n        @classmethod\n        def contents(cls) -> str:\n            \"\"\"\n            Return this file's own contents.\n            \"\"\"\n            assert cls._CONTENTS is not None, f\"{cls.__name__}.init not called\"\n            return cls._CONTENTS\n\n    class _Switcheroo:\n        \"\"\"\n        Management of the switcheroo procedure for running in a usable cgroup namespace and node.\n        \"\"\"\n\n        _CGROUP_ROOT = \"/sys/fs/cgroup\"\n        _CGROUP_NAME_PREFIX = \"codeeval_\"\n        _CGROUP_MAX_COUNT = 4096\n        _CGROUP_SANDBOX_NAME = \"sandbox\"\n        _CGROUP_SUPERVISOR_NAME = \"supervisor\"\n        _CGROUP_LEAF = \"leaf\"\n\n        def __init__(self, libc, log_path, max_sandbox_ram_bytes, do_resource_limiting):\n            self._libc = libc\n            self._log_path = log_path\n            self._max_sandbox_ram_bytes = max_sandbox_ram_bytes\n            self._do_resource_limiting = do_resource_limiting\n            self._my_euid = None\n            self._my_egid = None\n            self._checkpoint = None\n            self._cgroup_controllers = None\n            self._needed_controllers = set()\n            if max_sandbox_ram_bytes is not None:\n                self._needed_controllers.add(\"memory\")\n            self._initial_cgroup_name = None\n            self._codeeval_cgroup_name = None\n            self._moved = False\n            self._operations = [\n                # Save EUID and EGID before we move to a new user namespace.\n                (\"save_euid\", self._save_euid),\n                (\"save_egid\", self._save_egid),\n                (\"unshare_user\", self._unshare_user),\n                # Map our current user as being root in the new user namespace.\n                (\"write_uid_map\", self._write_uid_map),\n                (\"write_setgroups\", self._write_setgroups),\n                (\"write_gid_map\", self._write_gid_map),\n            ]\n            if do_resource_limiting:\n                self._operations.extend(\n                    (\n                        # cgroupfs's view does not take into account cgroup namespaces.\n                        # Weird, right?\n                        # This means `/proc/PID/cgroup` will show the namespaced view of\n                        # the cgroup that the PID is in, but `/sys/fs/cgroup` will still\n                        # contain the whole system cgroup hierarchy regardless of namespace.\n                        # Instead, namespaces act as \"boundary box\" around process movement\n                        # requests when writing to cgroup.procs or creating new cgroups.\n                        # So our first order of business here is to find out which cgroup we\n                        # are running in. We do this by scanning the whole cgroupfs hierarchy\n                        # and looking for our PID. This will populate\n                        # `self._initial_cgroup_name`.\n                        (\n                            \"find_self_in_cgroup_hierarchy\",\n                            self._find_self_in_cgroup_hierarchy,\n                        ),\n                        # The cgroup nesting rules are complicated, but the short of it is:\n                        # A cgroup can either **contain processes** OR **have limits**.\n                        # Also, cgroups that contain processes must be leaf nodes.\n                        # Also, cgroups that enforce limits must have their parent cgroup\n                        # also have the same limit \"controller\" be active.\n                        # So we will have two types of cgroups:\n                        #  - Leaf nodes with no controllers\n                        #  - Non-leaf nodes with controllers\n                        # So initially, all the processes in the container's initial\n                        # namespace need to be moved out to a new leaf node,\n                        # otherwise we cannot turn on controllers on the initial\n                        # cgroup.\n                        # So we will set up the following hierarchy:\n                        #   /sys/fs/cgroup/$INITIAL:\n                        #     The cgroup where the container's processes were running\n                        #     the first time we run any Sandbox in the container.\n                        #     It may initially have no controllers enabled, but we will\n                        #     turn them on later.\n                        #   /sys/fs/cgroup/$INITIAL/leaf:\n                        #     The cgroup where the container's processes are moved to\n                        #     from the $INITIAL cgroup upon first run of any Sandbox in\n                        #     this container. When this code runs again, processes that\n                        #     are already in `$INITIAL/leaf` are not moved.\n                        #   /sys/fs/cgroup/$INITIAL/codeeval_$NUM:\n                        #     A per-Sandbox cgroup that never contains any processes.\n                        #     It will have controllers enabled on it but will never have\n                        #     specific limits enforced.\n                        #   /sys/fs/cgroup/$INITIAL/codeeval_$NUM/sandbox:\n                        #     A per-Sandbox cgroup that never contains any processes.\n                        #     It will have controllers enabled on it and will enforce\n                        #     resource limits for the processes running in its /leaf.\n                        #   /sys/fs/cgroup/$INITIAL/codeeval_$NUM/sandbox/leaf:\n                        #     A per-Sandbox cgroup that is running `runsc` (gVisor).\n                        #     It has no controllers enabled on it, but resources are\n                        #     being enforced by virtue of being a child of\n                        #     `$INITIAL/codeeval_$NUM/sandbox` which does enforce limits.\n                        #   /sys/fs/cgroup/$INITIAL/codeeval_$NUM/supervisor:\n                        #     A per-Sandbox cgroup that never contains any processes.\n                        #     It will have controllers enabled on it and will enforce\n                        #     resource limits for the processes running in its /leaf.\n                        #   /sys/fs/cgroup/$INITIAL/codeeval_$NUM/supervisor/leaf:\n                        #     A per-Sandbox cgroup that is running a Python interpreter\n                        #     that manages the lifetime of the `runsc` process.\n                        #     It will run `Sandbox.maybe_main`.\n                        #     It has no controllers enabled on it, but resources are\n                        #     being enforced by virtue of being a child of\n                        #     `$INITIAL/codeeval_$NUM/sandbox` which does enforce limits.\n                        #\n                        # This particular step creates the `$INITIAL/leaf` cgroup.\n                        # If already created, it does nothing.\n                        (\n                            \"create_initial_leaf_cgroup\",\n                            self._create_initial_leaf_cgroup,\n                        ),\n                        # Move all processes in `$INITIAL` to `$INITIAL/leaf`.\n                        (\n                            \"move_initial_cgroup_processes_to_initial_leaf_cgroup\",\n                            self._move_initial_cgroup_processes_to_initial_leaf_cgroup,\n                        ),\n                        # Read the cgroup controllers enabled in `$INITIAL`. This acts\n                        # as a bounding set on the ones we can enable in any child of it.\n                        (\"read_cgroup_controllers\", self._read_cgroup_controllers),\n                        # Cleanup old `$INITIAL/codeeval_*` cgroups that may be lying\n                        # around from past runs.\n                        (\"cleanup_old_cgroups\", self._cleanup_old_cgroups),\n                        # Create a new `$INITIAL/codeeval_$NUM` cgroup.\n                        (\"create_codeeval_cgroup\", self._create_codeeval_cgroup),\n                        # Create a new `$INITIAL/codeeval_$NUM/sandbox` cgroup.\n                        (\"create_sandbox_cgroup\", self._create_sandbox_cgroup),\n                        # Create a new `$INITIAL/codeeval_$NUM/sandbox/leaf` cgroup.\n                        (\n                            \"create_sandbox_leaf_cgroup\",\n                            self._create_sandbox_leaf_cgroup,\n                        ),\n                        # Create a new `$INITIAL/codeeval_$NUM/supervisor` cgroup.\n                        (\"create_supervisor_cgroup\", self._create_supervisor_cgroup),\n                        # Create a new `$INITIAL/codeeval_$NUM/supervisor/leaf` cgroup.\n                        (\n                            \"create_supervisor_leaf_cgroup\",\n                            self._create_supervisor_leaf_cgroup,\n                        ),\n                        # Add controllers to `$INITIAL`.\n                        (\n                            \"add_cgroup_controllers_to_root\",\n                            self._add_cgroup_controllers_to_root,\n                        ),\n                        # Add controllers to `$INITIAL/codeeval_$NUM`.\n                        (\n                            \"add_cgroup_controllers_to_codeeval\",\n                            self._add_cgroup_controllers_to_codeeval,\n                        ),\n                        # Add controllers to `$INITIAL/codeeval_$NUM/sandbox`.\n                        (\n                            \"add_cgroup_controllers_to_sandbox\",\n                            self._add_cgroup_controllers_to_sandbox,\n                        ),\n                        # Set resource limits on `$INITIAL/codeeval_$NUM`.\n                        (\"set_sandbox_cgroup_limits\", self._set_sandbox_cgroup_limits),\n                        # Add controllers to `$INITIAL/codeeval_$NUM/supervisor`.\n                        (\n                            \"add_cgroup_controllers_to_supervisor\",\n                            self._add_cgroup_controllers_to_supervisor,\n                        ),\n                        # Set resource limits on `$INITIAL/codeeval_$NUM/supervisor`.\n                        (\n                            \"set_supervisor_cgroup_limits\",\n                            self._set_supervisor_cgroup_limits,\n                        ),\n                        # Move current process to\n                        # `$INITIAL/codeeval_$NUM/supervisor/leaf`.\n                        (\n                            \"move_process_to_supervisor_leaf\",\n                            self._move_process_to_supervisor_leaf,\n                        ),\n                        # Double-check that we have moved to\n                        # `$INITIAL/codeeval_$NUM/supervisor/leaf`.\n                        (\"sanity_check_own_cgroup\", self._sanity_check_own_cgroup),\n                    )\n                )\n\n        def _status(self):\n            \"\"\"\n            Return the current switcheroo status.\n\n            :return: The last successful operation name, \"UNSTARTED\" if unstarted, or \"OK\" if all done, and some information.\n            \"\"\"\n            main_status = self._checkpoint\n            if self._checkpoint is None:\n                main_status = \"UNSTARTED\"\n            if self._checkpoint == self._operations[-1][0]:\n                main_status = \"OK\"\n            my_pid = os.getpid()\n            status_line = f\"{main_status} (euid={self._my_euid} egid={self._my_egid} pid={my_pid} do_resource_limiting={self._do_resource_limiting} initial_cgroup_name={self._initial_cgroup_name} codeeval_cgroup_name={self._codeeval_cgroup_name} controllers={self._cgroup_controllers})\"\n            if self._do_resource_limiting:\n                cgroupfs_data = []\n                for cgroup_components in (\n                    (self._initial_cgroup_name,),\n                    (self._initial_cgroup_name, self._CGROUP_LEAF),\n                    (self._initial_cgroup_name, self._codeeval_cgroup_name),\n                    (\n                        self._initial_cgroup_name,\n                        self._codeeval_cgroup_name,\n                        self._CGROUP_LEAF,\n                    ),\n                    (\n                        self._initial_cgroup_name,\n                        self._codeeval_cgroup_name,\n                        self._CGROUP_SUPERVISOR_NAME,\n                    ),\n                    (\n                        self._initial_cgroup_name,\n                        self._codeeval_cgroup_name,\n                        self._CGROUP_SUPERVISOR_NAME,\n                        self._CGROUP_LEAF,\n                    ),\n                    (\n                        self._initial_cgroup_name,\n                        self._codeeval_cgroup_name,\n                        self._CGROUP_SANDBOX_NAME,\n                    ),\n                    (\n                        self._initial_cgroup_name,\n                        self._codeeval_cgroup_name,\n                        self._CGROUP_SANDBOX_NAME,\n                        self._CGROUP_LEAF,\n                    ),\n                ):\n                    if any(c is None for c in cgroup_components):\n                        continue\n                    file_data = []\n                    for filename in (\"procs\", \"controllers\", \"subtree_control\"):\n                        data = None\n                        try:\n                            with self._open(\n                                self._cgroup_path(\n                                    *(cgroup_components + (f\"cgroup.{filename}\",))\n                                ),\n                                \"rb\",\n                            ) as f:\n                                data = f.read().decode(\"ascii\").replace(\"\\n\", \" \")\n                        except Exception as e:\n                            data = f\"[fail: {e}]\"\n                        file_data.append(f\"{filename}: {data}\")\n                    cgroup_components_joined = os.sep.join(cgroup_components)\n                    file_data_joined = \", \".join(file_data)\n                    cgroupfs_data.append(\n                        f\"{cgroup_components_joined}=[{file_data_joined}]\"\n                    )\n                if len(cgroupfs_data) > 0:\n                    cgroupfs_data_joined = \" \".join(cgroupfs_data)\n                    status_line += f\" {cgroupfs_data_joined}\"\n            return status_line\n\n        def _cgroup_path(self, *components):\n            assert all(\n                c is not None for c in components\n            ), f\"Tried to build cgroup path with not-yet-determined component: {components}\"\n            return os.path.join(self._CGROUP_ROOT, *(c for c in components if c))\n\n        def _log(self, log_f, message):\n            \"\"\"\n            Log a message to `log_f`.\n\n            :param log_f: Log file object.\n            \"\"\"\n            timestamp = time.strftime(\"%H:%M:%S\")\n            status = self._status()\n            log_f.write(f\"[{timestamp}] {message} [{status}]\\n\".encode(\"utf-8\"))\n\n        def do(self):\n            \"\"\"\n            Do the switcheroo.\n\n            :raises OSError: If anything goes wrong. Progress is saved.\n            \"\"\"\n            op_index = -1\n            for i, (op, _) in enumerate(self._operations):\n                if self._checkpoint == op:\n                    op_index = i\n                    break\n            with self._open(self._log_path, \"ab\") as log_f:\n\n                def do_log(s):\n                    return self._log(log_f, s)\n\n                for op, fn in self._operations[op_index + 1 :]:\n                    do_log(f\"Starting operation: {op}\")\n                    errors = []\n                    success = False\n                    for attempt in range(1, 4):\n                        try:\n                            fn()\n                        except OSError as e:\n                            do_log(f\"OSError #{attempt}: {op}: {e}\")\n                            errors.append(OSError(f\"OSError in {op} (#{attempt}): {e}\"))\n                        except Exception as e:\n                            do_log(f\"Exception #{attempt}: {op}: {e}\")\n                            errors.append(OSError(f\"{op} failed (#{attempt}): {e}\"))\n                        else:\n                            success = True\n                            break\n                        time.sleep(0.1)\n                    if success:\n                        self._checkpoint = op\n                        do_log(f\"Success: {op}\")\n                        continue\n                    assert len(errors) > 0, \"Logic error\"\n                    first_exception = errors[0]\n                    if len(errors) == 1:\n                        raise first_exception\n                    other_exceptions = \"; \".join(str(e) for e in errors[1:])\n                    raise errors[0].__class__(\n                        f\"{first_exception} (other attempts: {other_exceptions})\"\n                    )\n\n        def _best_effort_remove_cgroup_subtree(self, codeeval_name):\n            for cgroup_components in (\n                (\n                    self._initial_cgroup_name,\n                    codeeval_name,\n                    self._CGROUP_SANDBOX_NAME,\n                    self._CGROUP_LEAF,\n                ),\n                (\n                    self._initial_cgroup_name,\n                    codeeval_name,\n                    self._CGROUP_SUPERVISOR_NAME,\n                    self._CGROUP_LEAF,\n                ),\n                (self._initial_cgroup_name, codeeval_name, self._CGROUP_SANDBOX_NAME),\n                (\n                    self._initial_cgroup_name,\n                    codeeval_name,\n                    self._CGROUP_SUPERVISOR_NAME,\n                ),\n                (self._initial_cgroup_name, codeeval_name),\n            ):\n                try:\n                    os.rmdir(self._cgroup_path(*cgroup_components))\n                except OSError:\n                    pass\n\n        def cleanup(self):\n            if self._moved:\n                self._move_process_back()\n            if self._codeeval_cgroup_name is not None:\n                self._best_effort_remove_cgroup_subtree(self._codeeval_cgroup_name)\n\n        def _open(self, path, mode):\n            try:\n                return open(path, mode)\n            except OSError as e:\n                raise OSError(f\"opening {path} mode={mode}: {e}\")\n\n        def _save_euid(self):\n            self._my_euid = os.geteuid()\n\n        def _save_egid(self):\n            self._my_egid = os.getegid()\n\n        def _unshare_user(self):\n            Sandbox.unshare(\n                os.CLONE_NEWUSER if \"CLONE_NEWUSER\" in os.__dict__ else 0x10000000\n            )\n\n        def _write_uid_map(self):\n            with self._open(\"/proc/self/uid_map\", \"wb\") as uid_map_f:\n                uid_map_f.write(f\"0 {self._my_euid} 1\\n\".encode(\"ascii\"))\n\n        def _write_setgroups(self):\n            with self._open(\"/proc/self/setgroups\", \"wb\") as setgroups_f:\n                setgroups_f.write(b\"deny\")\n\n        def _write_gid_map(self):\n            with self._open(\"/proc/self/gid_map\", \"wb\") as gid_map_f:\n                gid_map_f.write(f\"0 {self._my_egid} 1\\n\".encode(\"ascii\"))\n\n        def _find_self_in_cgroup_hierarchy(self):\n            my_pid = os.getpid()\n            cgroup_root_slash = self._CGROUP_ROOT + os.sep\n            found_cgroup = None\n            num_checked = 0\n            num_except = 0\n            sample_exception = None\n            for dirpath, _, subfiles in os.walk(\n                self._CGROUP_ROOT, onerror=None, followlinks=False\n            ):\n                if dirpath != self._CGROUP_ROOT and not dirpath.startswith(\n                    cgroup_root_slash\n                ):\n                    continue\n                if \"cgroup.procs\" not in subfiles:\n                    continue\n                num_checked += 1\n                found_pid = False\n                try:\n                    with self._open(\n                        os.path.join(dirpath, \"cgroup.procs\"), \"rb\"\n                    ) as cgroup_procs_f:\n                        for line in cgroup_procs_f:\n                            for pid_str in line.strip().split(b\" \"):\n                                if not pid_str:\n                                    continue\n                                try:\n                                    pid = int(pid_str)\n                                except ValueError:\n                                    continue\n                                if pid == my_pid:\n                                    found_pid = True\n                                    break\n                except Exception as e:\n                    num_except += 1\n                    if sample_exception is None:\n                        sample_exception = e.__class__(f\"{dirpath}: {e}\")\n                    continue\n                if not found_pid:\n                    continue\n                current_cgroup = dirpath[len(cgroup_root_slash) :]\n                if found_cgroup is not None:\n                    raise OSError(\n                        f\"Found PID {my_pid} in two separate cgroups: {found_cgroup} and {current_cgroup}; racing with another process?\"\n                    )\n                found_cgroup = current_cgroup\n            if found_cgroup is None:\n                raise OSError(\n                    f\"PID {my_pid} could not be found in any cgroup (checked {num_checked} cgroups, {num_except} exceptions; sample: {sample_exception})\"\n                )\n            if found_cgroup.endswith(os.sep + self._CGROUP_LEAF):\n                found_cgroup = found_cgroup[: -len(os.sep + self._CGROUP_LEAF)]\n            self._initial_cgroup_name = found_cgroup\n\n        def _read_cgroup_controllers(self):\n            cgroup_controllers = []\n            with self._open(\n                self._cgroup_path(self._initial_cgroup_name, \"cgroup.controllers\"), \"rb\"\n            ) as cgroup_controllers_f:\n                for line in cgroup_controllers_f:\n                    for controller in line.strip().split(b\" \"):\n                        if controller and controller not in cgroup_controllers:\n                            cgroup_controllers.append(controller.decode(\"ascii\"))\n            self._cgroup_controllers = cgroup_controllers\n\n        def _cleanup_old_cgroups(self):\n            initial_cgroup_path = self._cgroup_path(self._initial_cgroup_name)\n            for filename in os.listdir(initial_cgroup_path):\n                if not filename.startswith(self._CGROUP_NAME_PREFIX):\n                    continue\n                cgroup_path = os.path.join(initial_cgroup_path, filename)\n                if not os.path.isdir(cgroup_path):\n                    continue\n                self._best_effort_remove_cgroup_subtree(filename)\n\n        def _create_initial_leaf_cgroup(self):\n            try:\n                os.mkdir(\n                    self._cgroup_path(self._initial_cgroup_name, self._CGROUP_LEAF),\n                    mode=0o755,\n                )\n            except FileExistsError:\n                pass\n\n        def _create_codeeval_cgroup(self):\n            for counter in range(0, self._CGROUP_MAX_COUNT):\n                codeeval_cgroup_name_candidate = f\"{self._CGROUP_NAME_PREFIX}{counter}\"\n                cgroup_path = self._cgroup_path(\n                    self._initial_cgroup_name, codeeval_cgroup_name_candidate\n                )\n                try:\n                    os.mkdir(cgroup_path, mode=0o755)\n                except FileExistsError:\n                    pass\n                else:\n                    self._codeeval_cgroup_name = codeeval_cgroup_name_candidate\n                    return\n            initial_cgroup_path_prefix = self._cgroup_path(\n                self._initial_cgroup_name, self._CGROUP_NAME_PREFIX\n            )\n            raise OSError(\n                f\"Out of cgroups (tried {initial_cgroup_path_prefix}NUM with NUM from 0 to {self._CGROUP_MAX_COUNT-1} and they all already exist)\"\n            )\n\n        def _create_sandbox_cgroup(self):\n            os.mkdir(\n                self._cgroup_path(\n                    self._initial_cgroup_name,\n                    self._codeeval_cgroup_name,\n                    self._CGROUP_SANDBOX_NAME,\n                ),\n                mode=0o755,\n            )\n\n        def _create_sandbox_leaf_cgroup(self):\n            os.mkdir(\n                self._cgroup_path(\n                    self._initial_cgroup_name,\n                    self._codeeval_cgroup_name,\n                    self._CGROUP_SANDBOX_NAME,\n                    self._CGROUP_LEAF,\n                ),\n                mode=0o755,\n            )\n\n        def _create_supervisor_cgroup(self):\n            os.mkdir(\n                self._cgroup_path(\n                    self._initial_cgroup_name,\n                    self._codeeval_cgroup_name,\n                    self._CGROUP_SUPERVISOR_NAME,\n                ),\n                mode=0o755,\n            )\n\n        def _create_supervisor_leaf_cgroup(self):\n            os.mkdir(\n                self._cgroup_path(\n                    self._initial_cgroup_name,\n                    self._codeeval_cgroup_name,\n                    self._CGROUP_SUPERVISOR_NAME,\n                    self._CGROUP_LEAF,\n                ),\n                mode=0o755,\n            )\n\n        def _add_cgroup_controllers_to(self, *cgroup_components):\n            add_controllers = tuple(\n                controller\n                for controller in self._cgroup_controllers\n                if controller in self._needed_controllers\n            )\n            cgroup_components = tuple(cgroup_components) + (\"cgroup.subtree_control\",)\n            cgroup_subtree_control_path = self._cgroup_path(*cgroup_components)\n            try:\n                with self._open(\n                    cgroup_subtree_control_path, \"wb\"\n                ) as cgroup_subtree_control_f:\n                    controllers_data = (\n                        \" \".join(f\"+{controller}\" for controller in add_controllers)\n                        + \"\\n\"\n                    )\n                    cgroup_subtree_control_f.write(controllers_data.encode(\"ascii\"))\n            except OSError as e:\n                raise OSError(\n                    f\"Adding controllers {add_controllers} on {cgroup_subtree_control_path}: {e}\"\n                )\n            got_controllers = set()\n            try:\n                with self._open(\n                    cgroup_subtree_control_path, \"rb\"\n                ) as cgroup_subtree_control_f:\n                    for line in cgroup_subtree_control_f:\n                        for controller in line.strip().split(b\" \"):\n                            if not controller:\n                                continue\n                            got_controllers.add(controller.decode(\"ascii\"))\n            except OSError as e:\n                raise OSError(\n                    f\"Reading controllers from {cgroup_subtree_control_path}: {e}\"\n                )\n            assert all(\n                controller in got_controllers for controller in add_controllers\n            ), f\"Missing controllers in {cgroup_subtree_control_path}: got {got_controllers} expected {add_controllers}\"\n\n        def _add_cgroup_controllers_to_root(self):\n            return self._add_cgroup_controllers_to(self._initial_cgroup_name)\n\n        def _add_cgroup_controllers_to_codeeval(self):\n            return self._add_cgroup_controllers_to(\n                self._initial_cgroup_name, self._codeeval_cgroup_name\n            )\n\n        def _add_cgroup_controllers_to_sandbox(self):\n            return self._add_cgroup_controllers_to(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SANDBOX_NAME,\n            )\n\n        def _add_cgroup_controllers_to_supervisor(self):\n            return self._add_cgroup_controllers_to(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SUPERVISOR_NAME,\n            )\n\n        def _move_initial_cgroup_processes_to_initial_leaf_cgroup(self):\n            initial_cgroup_procs_path = self._cgroup_path(\n                self._initial_cgroup_name, \"cgroup.procs\"\n            )\n            initial_leaf_cgroup_procs_path = self._cgroup_path(\n                self._initial_cgroup_name, self._CGROUP_LEAF, \"cgroup.procs\"\n            )\n            done_zero_pid = False\n            while True:\n                moving_process_pid = None\n                with self._open(\n                    initial_cgroup_procs_path, \"rb\"\n                ) as initial_cgroup_procs_f:\n                    for line in initial_cgroup_procs_f:\n                        if moving_process_pid is not None:\n                            continue\n                        for pid_str in line.strip().split(b\" \"):\n                            if not pid_str:\n                                continue\n                            try:\n                                pid = int(pid_str)\n                            except ValueError:\n                                continue\n                            if pid == 0:\n                                if done_zero_pid:\n                                    continue\n                                done_zero_pid = True\n                            moving_process_pid = pid\n                            break\n                if moving_process_pid is None:\n                    break\n                with self._open(\n                    initial_leaf_cgroup_procs_path, \"wb\"\n                ) as initial_leaf_cgroup_procs_f:\n                    initial_leaf_cgroup_procs_f.write(\n                        f\"{moving_process_pid}\\n\".encode(\"ascii\")\n                    )\n\n        def _move_process_to_supervisor_leaf(self):\n            supervisor_leaf_cgroup_procs_path = self._cgroup_path(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SUPERVISOR_NAME,\n                self._CGROUP_LEAF,\n                \"cgroup.procs\",\n            )\n            f = self._open(supervisor_leaf_cgroup_procs_path, \"wb\")\n            try:\n                f.write(b\"0\\n\")\n                self._moved = True\n            finally:\n                try:\n                    f.close()\n                except OSError:\n                    pass\n\n        def _move_process_back(self):\n            initial_leaf_cgroup_procs_path = self._cgroup_path(\n                self._initial_cgroup_name, self._CGROUP_LEAF, \"cgroup.procs\"\n            )\n            f = self._open(initial_leaf_cgroup_procs_path, \"wb\")\n            try:\n                f.write(b\"0\\n\")\n                self._moved = False\n            finally:\n                try:\n                    f.close()\n                except OSError:\n                    pass\n\n        def _set_cgroup_limits(self, *cgroup_components):\n            cgroup_components = tuple(cgroup_components) + (\"memory.max\",)\n            cgroup_memory_max_path = self._cgroup_path(*cgroup_components)\n            if self._max_sandbox_ram_bytes is not None:\n                try:\n                    with self._open(cgroup_memory_max_path, \"wb\") as memory_max_f:\n                        memory_max_f.write(\n                            f\"{self._max_sandbox_ram_bytes}\\n\".encode(\"ascii\")\n                        )\n                except OSError as e:\n                    raise OSError(\n                        f\"Trying to set max RAM limit to {self._max_sandbox_ram_bytes} bytes: {e}\"\n                    )\n            for swap_type in (\"swap\", \"zswap\"):\n                cgroup_swap_components = tuple(cgroup_components) + (\n                    f\"memory.{swap_type}.max\",\n                )\n                cgroup_swap_path = self._cgroup_path(*cgroup_swap_components)\n                if not os.path.exists(cgroup_swap_path):\n                    continue\n                try:\n                    with self._open(cgroup_swap_path, \"wb\") as swap_max_f:\n                        swap_max_f.write(\"0\\n\".encode(\"ascii\"))\n                except OSError as e:\n                    raise OSError(\n                        f\"Trying to set max {swap_type} limit to 0 bytes: {e}\"\n                    )\n\n        def _set_supervisor_cgroup_limits(self):\n            return self._set_cgroup_limits(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SUPERVISOR_NAME,\n            )\n\n        def _set_sandbox_cgroup_limits(self):\n            return self._set_cgroup_limits(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SANDBOX_NAME,\n            )\n\n        def _sanity_check_own_cgroup(self):\n            supervisor_cgroup_path = self._cgroup_path(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SUPERVISOR_NAME,\n            )\n            with self._open(\"/proc/self/cgroup\", \"rb\") as cgroup_f:\n                cgroup_data = cgroup_f.read().decode(\"ascii\").strip()\n            assert cgroup_data.endswith(\n                os.sep + os.path.join(self._CGROUP_SUPERVISOR_NAME, self._CGROUP_LEAF)\n            ), f\"Unexpected self cgroup after moving to {supervisor_cgroup_path}: {cgroup_data}\"\n\n        def move_process_to_sandbox_leaf_cgroup_lambda(self):\n            \"\"\"\n            Returns a function that can move the current process to the sandbox leaf cgroup.\n\n            :return: A function to move the current process to the sandbox cgroup.\n            :raises SandboxException: If not queried after we have already chosen a new cgroup name.\n            \"\"\"\n            if not self._do_resource_limiting:\n                return lambda: None\n            if self._codeeval_cgroup_name is None:\n                raise Sandbox.SandboxException(\n                    \"Tried to move process to sandbox leaf cgroup before we know it\"\n                )\n\n            def _move(cgroup_path):\n                \"\"\"Dependency-free preexec_fn-compatible function to move to the given cgroup.procs.\"\"\"\n                try:\n                    f = open(cgroup_path, \"wb\")\n                except OSError as e:\n                    raise OSError(f\"Cannot open cgroup path {cgroup_path}: {e}\")\n                try:\n                    f.write(b\"0\\n\")\n                except OSError as e:\n                    raise OSError(f\"Cannot move process to {cgroup_path}: {e}\")\n                finally:\n                    try:\n                        f.close()\n                    except OSError:\n                        pass\n                clone_newcgroup = (\n                    os.CLONE_NEWCGROUP\n                    if \"CLONE_NEWCGROUP\" in os.__dict__\n                    else 0x2000000\n                )\n                if \"unshare\" in os.__dict__:  # Python >= 3.12.\n                    try:\n                        os.unshare(clone_newcgroup)\n                    except OSError as e:\n                        raise OSError(f\"unshare({clone_newcgroup}) failed: {e}\")\n                else:\n                    import ctypes\n\n                    libc = ctypes.CDLL(None)\n                    libc.unshare.argtypes = [ctypes.c_int]\n                    rc = libc.unshare(clone_newcgroup)\n                    if rc == -1:\n                        raise OSError(f\"unshare({clone_newcgroup}) failed\")\n\n            sandbox_cgroup_procs_path = self._cgroup_path(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SANDBOX_NAME,\n                self._CGROUP_LEAF,\n                \"cgroup.procs\",\n            )[:]\n            return lambda: _move(sandbox_cgroup_procs_path)\n\n        def monitor_cgroup_resources(self):\n            \"\"\"\n            Spawns a background thread that monitors resources, if limiting is enabled.\n            cgroups should be taking care of this, but some systems do not\n            enforce this. So this does the same in userspace.\n            Better than nothing.\n\n            :return: A function to cancel the monitor thread, if resource limiting is enabled.\n            \"\"\"\n            if not self._do_resource_limiting:\n                return lambda: None\n            self_memory_path = self._cgroup_path(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                \"memory.peak\",\n            )\n            sandbox_procs_path = self._cgroup_path(\n                self._initial_cgroup_name,\n                self._codeeval_cgroup_name,\n                self._CGROUP_SANDBOX_NAME,\n                self._CGROUP_LEAF,\n                \"cgroup.procs\",\n            )\n\n            def _kill():\n                new_pids_to_kill = True\n                pids_to_kill = set()\n                while new_pids_to_kill:\n                    prev_pids_to_kill_len = len(pids_to_kill)\n                    with self._open(sandbox_procs_path, \"rb\") as cgroup_procs_f:\n                        for line in cgroup_procs_f:\n                            for pid_str in line.strip().split(b\" \"):\n                                if not pid_str:\n                                    continue\n                                try:\n                                    pid = int(pid_str)\n                                except ValueError:\n                                    continue\n                                if pid != 0:\n                                    pids_to_kill.add(pid)\n                    for pid_to_kill in pids_to_kill:\n                        try:\n                            os.kill(pid_to_kill, signal.SIGKILL)\n                        except Exception:\n                            pass\n                    new_pids_to_kill = prev_pids_to_kill_len < len(pids_to_kill)\n\n            def _monitor():\n                if self._max_sandbox_ram_bytes is not None:\n                    try:\n                        with self._open(self_memory_path, \"rb\") as memory_peak_f:\n                            memory_peak_bytes = int(\n                                memory_peak_f.read().decode(\"ascii\").strip()\n                            )\n                        if memory_peak_bytes > self._max_sandbox_ram_bytes:\n                            _kill()\n                    except Exception as e:\n                        print(\n                            f\"Warning: Failed to enforce code execution RAM: {e}\",\n                            file=sys.stderr,\n                        )\n\n            lock = threading.Lock()\n            enabled = [True]\n\n            def _loop():\n                while True:\n                    time.sleep(0.1)\n                    with lock:\n                        if not enabled[0]:\n                            break\n                    _monitor()\n\n            monitor_thread = threading.Thread(\n                target=_loop, name=\"Monitor thread for code execution\", daemon=True\n            )\n            monitor_thread.start()\n\n            def _cancel():\n                with lock:\n                    enabled[0] = False\n                monitor_thread.join()\n\n            return _cancel\n\n    class SandboxException(Exception):\n        \"\"\"\n        Base class for all exceptions generated by `Sandbox`.\n        \"\"\"\n\n        def __init__(self, *args, **kwargs):\n            self._sandbox_exception_args = tuple(args)\n            self._sandbox_exception_kwargs = dict(kwargs)\n            super().__init__(*args, **kwargs)\n\n    class PlatformNotSupportedException(SandboxException):\n        \"\"\"\n        Raised when the sandbox cannot run on the current platform.\n        The only way to fix this is to run on a different platform.\n        \"\"\"\n\n    class SandboxRuntimeException(SandboxException):\n        \"\"\"\n        Raised when the sandbox fails to run properly.\n        This means gVisor itself is failing, not the code in the sandbox.\n        \"\"\"\n\n    class ExecutionError(subprocess.CalledProcessError):\n        \"\"\"\n        Raised when the sandboxed code fails to run.\n        This means the sandbox worked, but the code that ran within failed.\n        \"\"\"\n\n        def __init__(self, code, **kwargs):\n            super().__init__(**kwargs)\n            self._code = code\n            self._sandbox_exception_args = ()\n            self._sandbox_exception_kwargs = kwargs.copy()\n            self._sandbox_exception_kwargs[\"code\"] = code\n\n        def __str__(self):\n            super_str = super().__str__()\n            full_code = self._code\n            short_code = full_code.replace(\"\\n\", \";\")\n            if len(short_code) >= 128:\n                short_code = short_code[:60] + \"\\u2026\" + short_code[-60:]\n            if self.stderr:\n                lines = [\n                    line.strip() for line in self.stderr.split(\"\\n\") if line.strip()\n                ]\n                if len(lines) >= 2:\n                    first_line, last_line = lines[0], lines[-1]\n                    return f\"{first_line} [\\u2026] {last_line} (`{short_code}`)\\n{super_str}\\n```\\n{full_code}\\n```\"\n                if len(lines) == 1:\n                    first_line = lines[0]\n                    return f\"{first_line} (`{short_code}`)\\n{super_str}\\n```\\n{full_code}\\n```\"\n            return f\"`{short_code}` failed\\n{super_str}\\n```\\n{full_code}\\n```\"\n\n    class CodeExecutionError(ExecutionError):\n        \"\"\"\n        Raised when the sandboxed code returns with a non-zero exit code.\n        \"\"\"\n\n        def __str__(self):\n            super_str = super().__str__()\n            return f\"Code error: {super_str}\"\n\n    class ExecutionTimeoutError(ExecutionError):\n        \"\"\"\n        Raised when the code runs for too long relative to the timeout.\n        \"\"\"\n\n        def __str__(self):\n            super_str = super().__str__()\n            return f\"Timeout: {super_str}\"\n\n    class InterruptedExecutionError(ExecutionError):\n        \"\"\"\n        Raised when the code runs but is interrupted before it finishes.\n        This could happen from running out of resources.\n        \"\"\"\n\n        def __str__(self):\n            super_str = super().__str__()\n            return f\"Interrupted: {super_str}\"\n\n    class FixableException(SandboxException):\n        \"\"\"\n        Base class for exceptions which can be addressed by the user.\n        \"\"\"\n\n    class GVisorNotInstalledException(FixableException):\n        \"\"\"\n        Raised when gVisor is not installed (`runsc` not found in $PATH).\n        \"\"\"\n\n    class CorruptDownloadException(FixableException):\n        \"\"\"\n        Raised when auto-downloading gVisor resulted in a hash mismatch.\n        \"\"\"\n\n    class EnvironmentNeedsSetupException(FixableException):\n        \"\"\"\n        Raised when the environment does not give adequate control over the\n        system to run gVisor properly.\n        \"\"\"\n\n    @classmethod\n    def check_platform(cls):\n        \"\"\"\n        Verifies that this tool is running on a supported platform.\n\n        :return: Nothing.\n        :raises PlatformNotSupportedException: If running on an unsupported platform.\n        \"\"\"\n        uname = platform.uname()\n        if uname.system != \"Linux\":\n            raise cls.PlatformNotSupportedException(f\"{uname.system} is not supported\")\n        if uname.machine not in (\"x86_64\", \"aarch64\"):\n            raise cls.PlatformNotSupportedException(f\"{uname.machine} is not supported\")\n\n    @classmethod\n    def check_cgroups(cls):\n        \"\"\"\n        Verifies that cgroupfs is mounted and usable for resource limiting.\n\n        :return: Nothing.\n        :raises EnvironmentNeedsSetupException: If cgroupfs is not mounted or unusable for resource limiting.\n        \"\"\"\n        if not os.path.exists(\"/sys/fs/cgroup\"):\n            raise cls.EnvironmentNeedsSetupException(\n                \"cgroupfs not mounted as /sys/fs/cgroup but necessary for the sandbox to enforce memory limits; please mount it (`--mount=type=bind,source=/sys/fs/cgroup,target=/sys/fs/cgroup,readonly=false`), or disable resource limiting if appropriate\"\n            )\n        if not os.path.exists(\"/sys/fs/cgroup/cgroup.subtree_control\"):\n            raise cls.EnvironmentNeedsSetupException(\n                \"/sys/fs/cgroup/cgroup.subtree_control not found; make sure you are using cgroups v2, or disable resource limiting if appropriate\"\n            )\n        # Try to open the file for writing to see if we can actually control cgroups.\n        # They may be mounted read-only, as is default with Docker.\n        try:\n            with open(\n                \"/sys/fs/cgroup/cgroup.subtree_control\", \"wb\"\n            ) as subtree_control_f:\n                pass\n        except OSError:\n            if os.geteuid() != 0:\n                raise cls.EnvironmentNeedsSetupException(\n                    \"This script is not running as root, but it needs to do so in order to enforce resource limits; please run as root, or disable resource limiting if appropriate\"\n                )\n            raise cls.EnvironmentNeedsSetupException(\n                \"cgroupfs is not mounted writable but necessary for the sandbox to enforce memory limits; please remount it as writable (`--mount=type=bind,source=/sys/fs/cgroup,target=/sys/fs/cgroup,readonly=false`), or disable resource limiting if appropriate\"\n            )\n        with open(\"/sys/fs/cgroup/cgroup.controllers\", \"rb\") as subtree_control_f:\n            controllers = subtree_control_f.read().decode(\"ascii\").split(\" \")\n        if \"memory\" not in controllers:\n            raise cls.EnvironmentNeedsSetupException(\n                \"cgroupfs does not have the 'memory' controller enabled, necessary to enforce memory limits; please enable it, or disable resource limiting if appropriate\"\n            )\n\n    @classmethod\n    def check_procfs(cls):\n        \"\"\"\n        Verifies that we have an unobstructed view of procfs.\n\n        :return: Nothing.\n        :raises EnvironmentNeedsSetupException: If procfs is obstructed.\n        \"\"\"\n        mount_infos = []\n        with open(\"/proc/self/mountinfo\", \"rb\") as mountinfo_f:\n            for line in mountinfo_f:\n                line = line.decode(\"utf-8\").strip()\n                if not line:\n                    continue\n                mount_components = line.split(\" \")\n                if len(mount_components) < 10:\n                    continue\n                hyphen_index = mount_components.index(\"-\")\n                if hyphen_index < 6:\n                    continue\n                mount_info = {\n                    \"mount_path\": mount_components[4],\n                    \"path_within_mount\": mount_components[3],\n                    \"fs_type\": mount_components[hyphen_index + 1],\n                }\n                mount_infos.append(mount_info)\n        procfs_mounts = frozenset(\n            m[\"mount_path\"]\n            for m in mount_infos\n            if m[\"fs_type\"] == \"proc\" and m[\"path_within_mount\"] == \"/\"\n        )\n        if len(procfs_mounts) == 0:\n            raise cls.EnvironmentNeedsSetupException(\n                \"procfs is not mounted; please mount it\"\n            )\n        obstructed_procfs_mounts = set()\n        for mount_info in mount_infos:\n            for procfs_mount in procfs_mounts:\n                if mount_info[\"mount_path\"].startswith(procfs_mount + os.sep):\n                    obstructed_procfs_mounts.add(procfs_mount)\n        for procfs_mount in procfs_mounts:\n            if procfs_mount not in obstructed_procfs_mounts:\n                return  # We have at least one unobstructed procfs view.\n        assert len(obstructed_procfs_mounts) > 0, \"Logic error\"\n        raise cls.EnvironmentNeedsSetupException(\n            \"procfs is obstructed; please mount a new procfs mount somewhere in the container, e.g. /proc2 (`--mount=type=bind,source=/proc,target=/proc2,readonly=false,bind-recursive=disabled`)\"\n        )\n\n    @classmethod\n    def unshare(cls, flags):\n        \"\"\"\n        Implementation of `os.unshare` that works on Python < 3.12.\n\n        :param flags: Flags to pass to the `unshare(2)` system call.\n        :raises OSError: If something goes wrong.\n        \"\"\"\n        if \"unshare\" in os.__dict__:  # Python >= 3.12.\n            return os.unshare(flags)\n\n        # Python <= 3.11:\n        return cls._libc().unshare(flags)\n\n    @classmethod\n    def check_unshare(cls):\n        \"\"\"\n        Verifies that the `unshare(2)` system call is available.\n\n        :return: Nothing.\n        :raises EnvironmentNeedsSetupException: If `unshare(2)` is not available.\n        \"\"\"\n        try:\n            cls.unshare(0)\n        except OSError:\n            raise cls.EnvironmentNeedsSetupException(\n                \"`unshare(2)` syscall is unavailable but necessary for the sandbox to isolate itself; please remove the seccomp filter (`--security-opt=seccomp=unconfined`)\"\n            )\n\n    @classmethod\n    def get_runsc_path(cls):\n        \"\"\"\n        Returns the absolute path where the `runsc` binary is installed.\n\n        :return: Absolute path to `runsc` binary, or `None` if not installed.\n        \"\"\"\n        runsc_path = shutil.which(\"runsc\")\n        if runsc_path:\n            return runsc_path\n        if os.path.exists(cls.AUTO_INSTALLATION_PATH):\n            return cls.AUTO_INSTALLATION_PATH\n        return None\n\n    @classmethod\n    def runsc_needs_installation(cls):\n        \"\"\"\n        Checks whether the `runsc` binary is installed.\n\n        :return: Whether the `runsc` binary is installed.\n        \"\"\"\n        return cls.get_runsc_path() is None\n\n    @classmethod\n    def install_runsc(cls):\n        \"\"\"\n        Download and install the `runsc` binary if not already present.\n\n        :return: Nothing.\n        :raises CorruptDownloadException: If the download resulted in a hash mismatch.\n        \"\"\"\n        if not cls.runsc_needs_installation():\n            return\n        uname = platform.uname()\n        release_url_dir = f\"https://storage.googleapis.com/gvisor/releases/release/latest/{uname.machine}\"\n        os.makedirs(\n            os.path.dirname(cls.AUTO_INSTALLATION_PATH), mode=0o755, exist_ok=True\n        )\n        with tempfile.TemporaryDirectory(\n            prefix=\"sandbox_download_\"\n        ) as download_tmp_dir:\n            download_path = os.path.join(download_tmp_dir, \"runsc\")\n            urllib.request.urlretrieve(\n                url=f\"{release_url_dir}/runsc\",\n                filename=download_path,\n            )\n            sha512_raw = urllib.request.urlopen(\n                f\"{release_url_dir}/runsc.sha512\"\n            ).read()\n            want_sha512 = sha512_raw.decode(\"ascii\").split(\" \")[0]\n            runsc_hash = hashlib.sha512()\n            with open(download_path, \"rb\") as runsc_f:\n                while True:\n                    chunk = runsc_f.read(65536)\n                    if not chunk:\n                        break\n                    runsc_hash.update(chunk)\n            runsc_sha512 = runsc_hash.hexdigest()\n            if runsc_sha512 != want_sha512:\n                raise cls.CorruptDownloadException(\n                    \"gVisor hash mismatch when auto-installing; please install gVisor manually\"\n                )\n            os.chmod(download_path, mode=0o755)\n            os.rename(download_path, cls.AUTO_INSTALLATION_PATH)\n\n    @classmethod\n    def check_setup(\n        cls,\n        language: str,\n        auto_install_allowed: bool,\n        require_resource_limiting: bool,\n    ):\n        \"\"\"\n        Verifies that the environment is compatible with running sandboxes.\n\n        :param language: The programming language to run.\n        :param auto_install_allowed: Whether auto-installation of `runsc` is allowed.\n        :param require_resource_limiting: Check that the host supports resource limiting via cgroups.\n\n        :return: Nothing.\n        :raises ValueError: If provided an invalid language name.\n        :raises PlatformNotSupportedException: If running on an unsupported platform.\n        :raises FixableException: If another issue occurs but that can be fixed by the user.\n        \"\"\"\n        if language not in cls.SUPPORTED_LANGUAGES:\n            raise ValueError(f\"Unsupported language: {language}\")\n        if shutil.which(\"bash\") is None:\n            raise cls.EnvironmentNeedsSetupException(\n                \"bash is not installed (`bash` binary not found in $PATH); please install it\"\n            )\n        if shutil.which(\"unshare\") is None:\n            raise cls.EnvironmentNeedsSetupException(\n                \"unshare is not installed (`unshare` binary not found in $PATH); please install it\"\n            )\n        cls.check_platform()\n        cls.check_unshare()\n        if require_resource_limiting:\n            cls.check_cgroups()\n        cls.check_procfs()\n        if not auto_install_allowed and cls.get_runsc_path() is None:\n            raise cls.GVisorNotInstalledException(\n                \"gVisor is not installed (runsc binary not found in $PATH); please install it or enable AUTO_INSTALL valve for auto installation\"\n            )\n\n    @classmethod\n    def _libc(cls):\n        if cls._LIBC is None:\n            cls._LIBC = cls._Libc()\n        return cls._LIBC\n\n    @classmethod\n    def main(cls):\n        \"\"\"\n        Entry-point for (re-)execution.\n        Must be called during import.\n        May call `sys.exit` if this is intended to be a code evaluation re-execution.\n        \"\"\"\n        cls._SelfFile.init()\n        if cls._MARKER_ENVIRONMENT_VARIABLE not in os.environ:\n            return\n        directives = json.load(sys.stdin)\n        try:\n            result = cls(**directives[\"settings\"])._run()\n        except Exception as e:\n            exception_info = {\n                \"name\": e.__class__.__name__,\n                \"str\": str(e),\n            }\n            if isinstance(e, cls.SandboxException) or isinstance(e, cls.ExecutionError):\n                exception_info[\"args\"] = e._sandbox_exception_args\n                exception_info[\"kwargs\"] = e._sandbox_exception_kwargs\n            json.dump(\n                {\n                    \"exception\": exception_info,\n                },\n                sys.stdout,\n            )\n        else:\n            stdout = result.stdout\n            if type(stdout) is not type(b\"\"):\n                stdout = stdout.encode(\"utf-8\", errors=\"replace\")\n            stderr = result.stderr\n            if type(stderr) is not type(b\"\"):\n                stderr = stderr.encode(\"utf-8\", errors=\"replace\")\n            json.dump(\n                {\n                    \"result\": {\n                        \"args\": result.args,\n                        \"returncode\": result.returncode,\n                        \"stdout\": base64.b64encode(stdout).decode(\"utf-8\"),\n                        \"stderr\": base64.b64encode(stderr).decode(\"utf-8\"),\n                    },\n                },\n                sys.stdout,\n            )\n        finally:\n            sys.stdout.flush()\n            sys.exit(0)\n\n    def __init__(\n        self,\n        tmp_dir: str,\n        language: str,\n        code: str,\n        debug: bool,\n        networking_allowed: bool,\n        max_runtime_seconds: int,\n        max_ram_bytes: typing.Optional[int] = None,\n        require_resource_limiting: bool = False,\n        persistent_home_dir: typing.Optional[str] = None,\n    ):\n        \"\"\"\n        Constructor.\n\n        :param tmp_dir: Temporary directory exclusive to this sandbox. Must outlive the Sandbox object.\n        :param language: The language of the code; must be one of `SUPPORTED_LANGUAGES`.\n        :param code: Arbitrary code that needs to run in the sandbox.\n        :param debug: Whether or not to enable debug-level logging for the sandbox.\n        :param networking_allowed: Whether the code should be given access to the network.\n        :param max_runtime_seconds: How long the code should be allowed to run, in seconds.\n        :param max_ram_bytes: How many bytes of RAM the interpreter should be allowed to use, or `None` for no limit.\n        :param require_resource_limiting: If true, refuse to launch a sandbox if the host doesn't support resource limiting via cgroups.\n        :param persistent_home_dir: Optional directory which will be mapped read-write to this real host directory.\n        \"\"\"\n        self._init(\n            {\n                \"tmp_dir\": tmp_dir,\n                \"language\": language,\n                \"code\": code,\n                \"debug\": debug,\n                \"networking_allowed\": networking_allowed,\n                \"max_runtime_seconds\": max_runtime_seconds,\n                \"max_ram_bytes\": max_ram_bytes,\n                \"require_resource_limiting\": require_resource_limiting,\n                \"persistent_home_dir\": persistent_home_dir,\n            }\n        )\n\n    def _init(self, settings):\n        self._settings = settings\n        self._tmp_dir = self._settings[\"tmp_dir\"]\n        self._bundle_path = os.path.join(self._tmp_dir, \"bundle\")\n        self._runtime_root_path = os.path.join(self._tmp_dir, \"runtime\")\n        self._logs_path = os.path.join(self._tmp_dir, \"logs\")\n        self._gotmp_dir = os.path.join(self._tmp_dir, \"gotmp\")\n        self._sandbox_shared_path = os.path.join(self._tmp_dir, \"sandbox\")\n        self._language = self._settings[\"language\"]\n        self._code = self._settings[\"code\"]\n        self._debug = self._settings[\"debug\"]\n        self._networking_allowed = self._settings[\"networking_allowed\"]\n        self._max_runtime_seconds = self._settings[\"max_runtime_seconds\"]\n        self._max_ram_bytes = self._settings[\"max_ram_bytes\"]\n        self._require_resource_limiting = self._settings[\n            \"require_resource_limiting\"\n        ] or all((self._max_ram_bytes is None,))\n        self._persistent_home_dir = self._settings[\"persistent_home_dir\"]\n        self._sandboxed_command = None\n        self._switcheroo = None\n\n    def _setup_sandbox(self):\n        \"\"\"\n        Set up the sandbox's root filesystem and OCI config prior to execution.\n        Runs in separate forked process. Performs the switcheroo.\n\n        :raises FixableException: If an issue occurs but that can be fixed by the user.\n        \"\"\"\n        # Set up basic configuration options.\n        oci_config = copy.deepcopy(self.OCI_CONFIG_SKELETON)\n        if self._max_ram_bytes:\n            oci_config[\"linux\"][\"resources\"][\"memory\"][\"limit\"] = self._max_ram_bytes\n        os.makedirs(self._bundle_path, mode=0o711)\n        os.makedirs(self._runtime_root_path, mode=0o711)\n        os.makedirs(self._logs_path, mode=0o711)\n        os.makedirs(self._sandbox_shared_path, mode=0o777)\n        os.makedirs(self._gotmp_dir, mode=0o711)\n        os.chmod(self._sandbox_shared_path, mode=0o777, follow_symlinks=False)\n        rootfs_path = os.path.join(self._tmp_dir, \"rootfs\")\n        os.makedirs(rootfs_path, mode=0o755)\n        if self._persistent_home_dir is not None:\n            if not os.path.isdir(self._persistent_home_dir):\n                raise self.SandboxException(\n                    f\"Persistent home directory {self._persistent_home_dir} does not exist\"\n                )\n        oci_config[\"root\"][\"path\"] = rootfs_path\n        do_resource_limiting = True\n        if not self._require_resource_limiting:\n            try:\n                self.check_cgroups()\n            except self.EnvironmentNeedsSetupException:\n                do_resource_limiting = False\n        self._switcheroo = self._Switcheroo(\n            libc=self._libc(),\n            log_path=os.path.join(self._logs_path, \"switcheroo.txt\"),\n            max_sandbox_ram_bytes=self._max_ram_bytes,\n            do_resource_limiting=do_resource_limiting,\n        )\n        try:\n            self._switcheroo.do()\n        except Exception as e:\n            try:\n                switcheroo_status = self._switcheroo._status()\n            except Exception:\n                raise e\n            else:\n                raise e.__class__(f\"{e}; {switcheroo_status}\")\n\n        # Locate the interpreter to use.\n        interpreter_path = sys.executable\n        if self._language == self.LANGUAGE_BASH:\n            interpreter_path = shutil.which(\"bash\")\n        if interpreter_path is None:\n            raise RuntimeError(\"Interpreter not found\")\n        oci_config[\"mounts\"].append(\n            {\n                \"type\": \"bind\",\n                \"source\": interpreter_path,\n                \"destination\": interpreter_path,\n                \"options\": [\"ro\"],\n            }\n        )\n\n        # Populate rootfs. This is a multi-step process.\n\n        # Create writable empty directories.\n        for d in self.EMPTY_WRITABLE_DIRECTORIES:\n            rootfs_subdir = os.path.join(rootfs_path, d.removeprefix(os.path.sep))\n            os.makedirs(rootfs_subdir, mode=0o755, exist_ok=True)\n            oci_config[\"mounts\"].append(\n                {\n                    \"type\": \"tmpfs\",\n                    \"destination\": d,\n                    \"options\": [],\n                }\n            )\n\n        # Create read-only empty directories.\n        for d in self.EMPTY_READ_ONLY_DIRECTORIES + [os.path.dirname(interpreter_path)]:\n            rootfs_subdir = os.path.join(rootfs_path, d.removeprefix(os.path.sep))\n            os.makedirs(rootfs_subdir, mode=0o755, exist_ok=True)\n\n        # Handle exposed host symlinks. These will show up as symlinks with the same\n        # target path in the sandbox, so they do not expose the host's view of the\n        # directory they point to.\n        symlinks = set()\n        for p in self.EXPOSED_SYSTEM_DIRECTORIES + self.EXPOSED_SYSTEM_FILES:\n            if not os.path.islink(p):\n                continue\n            rootfs_subpath = os.path.join(rootfs_path, p.removeprefix(os.path.sep))\n            os.makedirs(os.path.dirname(rootfs_subpath), mode=0o755, exist_ok=True)\n            os.symlink(src=os.readlink(p), dst=rootfs_subpath)\n            symlinks.add(p)\n\n        # Handle exposed host directories.\n        for d in self.EXPOSED_SYSTEM_DIRECTORIES:\n            if d in symlinks:\n                continue  # It is a symlink, so already handled.\n            if not os.path.isdir(d):\n                continue  # The host does not have a directory at this path.\n            rootfs_subdir = os.path.join(rootfs_path, d.removeprefix(os.path.sep))\n            os.makedirs(rootfs_subdir, mode=0o755, exist_ok=True)\n            oci_config[\"mounts\"].append(\n                {\n                    \"type\": \"bind\",\n                    \"source\": d,\n                    \"destination\": d,\n                    \"options\": [\"ro\", \"rbind\"],\n                }\n            )\n\n        # Handle exposed host files.\n        for f in self.EXPOSED_SYSTEM_FILES:\n            if f in symlinks:\n                continue  # It is a symlink, so already handled.\n            if not os.path.isfile(f):\n                continue  # The host does not have a file at this path.\n            rootfs_subpath = os.path.join(rootfs_path, f.removeprefix(os.path.sep))\n            rootfs_subdir = os.path.dirname(rootfs_subpath)\n            os.makedirs(rootfs_subdir, mode=0o755, exist_ok=True)\n            oci_config[\"mounts\"].append(\n                {\n                    \"type\": \"bind\",\n                    \"source\": f,\n                    \"destination\": f,\n                    \"options\": [\"ro\"],\n                }\n            )\n\n        # Shared sandbox directory to propagate exit code and persistent files.\n        oci_config[\"mounts\"].append(\n            {\n                \"type\": \"bind\",\n                \"source\": self._sandbox_shared_path,\n                \"destination\": \"/sandbox\",\n                \"options\": [\"rw\"],\n            }\n        )\n        if self._persistent_home_dir is not None:\n            oci_config[\"mounts\"].append(\n                {\n                    \"type\": \"bind\",\n                    \"source\": self._persistent_home_dir,\n                    \"destination\": \"/sandbox/persistent\",\n                    \"options\": [\"rw\"],\n                }\n            )\n\n        # Sort mounts to ensure proper overlay order.\n        oci_config[\"mounts\"].sort(key=lambda m: m[\"destination\"])\n\n        # Generate some /etc files that look normal.\n        with open(os.path.join(rootfs_path, \"etc/hostname\"), \"w\") as hostname_f:\n            hostname_f.write(\"sandbox\\n\")\n        with open(os.path.join(rootfs_path, \"etc/passwd\"), \"w\") as passwd_f:\n            passwd_f.write(\"user:x:1000:1000:user:/home/user:/bin/bash\\n\")\n\n        # Generate command line to run in the sandbox.\n        self._sandboxed_command = [\n            shutil.which(\"bash\"),\n            \"-c\",\n            \"; \".join(\n                (\n                    \"echo OK > /sandbox/started\",\n                    f\"{interpreter_path} /dev/stdin\",\n                    'echo \"$?\" > /sandbox/.pre_exit_code || exit 1',\n                    \"if [[ -d /sandbox/persistent ]]; then cp -rd --one-file-system /home/user/. /sandbox/persistent/ || exit 2; fi\",\n                    \"mv /sandbox/.pre_exit_code /sandbox/exit_code || exit 3\",\n                    \"exit 0\",\n                )\n            ),\n        ]\n\n        # Work around issue that gVisor does not preserve correct UID mappings when running as non-root user in the sandbox.\n        # So map current user to 0:0, then create a new user namespace immediately before running command and remap to\n        # correct UID/GID.\n        oci_config[\"process\"][\"user\"][\"uid\"] = 0\n        oci_config[\"process\"][\"user\"][\"gid\"] = 0\n        oci_config[\"process\"][\"args\"] = [\n            shutil.which(\"unshare\"),\n            \"--map-user=1000\",\n            \"--map-group=1000\",\n        ] + self._sandboxed_command\n\n        # We are done. Write OCI config to bundle directory.\n        with open(os.path.join(self._bundle_path, \"config.json\"), \"w\") as bundle_f:\n            json.dump(oci_config, bundle_f, indent=2, sort_keys=True)\n\n    def _run(self) -> subprocess.CompletedProcess:\n        \"\"\"\n        Spawn and wait for the sandbox. Runs in separate forked process.\n\n        :return: A `CompletedProcess` object representing the return code and stdout/stderr of the code interpreter.\n        :raises Sandbox.SandboxRuntimeException: If the sandbox failed to start or behaved incorrectly regardless of the code being evaluated.\n        :raises Sandbox.ExecutionTimeoutError: If the code interpreter ran for longer than configured.\n        :raises Sandbox.InterruptedExecutionError: If the code interpreter died without providing a return code; usually due to running over resource limits.\n        :raises sandbox.CodeExecutionError: If the code interpreter failed to execute the given code. This does not represent a sandbox failure.\n        \"\"\"\n        try:\n            self._setup_sandbox()\n\n            network_mode = \"host\" if self._networking_allowed else \"none\"\n            runsc_argv = [\n                self.get_runsc_path(),\n                \"--rootless=true\",\n                \"--directfs=false\",\n                f\"--network={network_mode}\",\n                \"--ignore-cgroups=true\",  # We already took care of cgroups manually.\n                f\"--root={self._runtime_root_path}\",\n                f\"--debug-log={self._logs_path}/\",\n                \"run\",\n                f\"--bundle={self._bundle_path}\",\n                \"sandbox\",\n            ]\n            runsc_env = os.environ.copy()\n            runsc_env[\"TMPDIR\"] = self._gotmp_dir\n            started_marker_path = os.path.join(self._sandbox_shared_path, \"started\")\n            resource_monitor_cancel = self._switcheroo.monitor_cgroup_resources()\n            try:\n                result = subprocess.run(\n                    runsc_argv,\n                    env=runsc_env,\n                    preexec_fn=self._switcheroo.move_process_to_sandbox_leaf_cgroup_lambda(),\n                    input=self._code + \"\\n\",\n                    text=True,\n                    capture_output=True,\n                    timeout=self._max_runtime_seconds,\n                    check=True,\n                )\n            except subprocess.TimeoutExpired as e:\n                raise self.ExecutionTimeoutError(\n                    code=self._code,\n                    returncode=126,\n                    cmd=self._sandboxed_command,\n                    output=e.stdout,\n                    stderr=e.stderr,\n                )\n            except subprocess.CalledProcessError as e:\n                if os.path.isfile(started_marker_path):\n                    raise self.InterruptedExecutionError(\n                        code=self._code,\n                        returncode=127,\n                        cmd=self._sandboxed_command,\n                        output=e.stdout,\n                        stderr=e.stderr,\n                    )\n                logs = {}\n\n                def process_log(filename, log_line):\n                    if self._debug or (\n                        log_line and log_line[0] in \"WEF\"\n                    ):  # Warning, Error, Fatal\n                        if filename not in logs:\n                            logs[filename] = []\n                        logs[filename].append(log_line)\n\n                self.debug_logs(process_log)\n                stderr = e.stderr.strip()\n                json_logs = json.dumps(logs)\n                if self._debug:\n                    raise self.SandboxRuntimeException(\n                        f\"Sandbox failed to start: {e}; stderr: {stderr}; logs: {json_logs}\"\n                    )\n                raise self.SandboxRuntimeException(\n                    f\"Sandbox failed to start: {e} (turn on debug mode to see more information); stderr: {stderr}; logs: {json_logs}\"\n                )\n            finally:\n                resource_monitor_cancel()\n            if not os.path.isfile(started_marker_path):\n                raise self.SandboxRuntimeException(\n                    \"Sandbox failed to start up properly\"\n                )\n            exit_code_path = os.path.join(self._sandbox_shared_path, \"exit_code\")\n            if not os.path.isfile(exit_code_path):\n                raise self.SandboxRuntimeException(\n                    \"Sandbox failed to record an exit code\"\n                )\n            with open(exit_code_path, \"r\") as exit_code_f:\n                exit_code_str = exit_code_f.read()\n            try:\n                exit_code = int(exit_code_str.strip())\n            except ValueError as e:\n                raise self.SandboxRuntimeException(\n                    f\"Sandbox recorded non-integer exit code: {e}\"\n                )\n            if exit_code != 0:\n                raise self.CodeExecutionError(\n                    code=self._code,\n                    returncode=exit_code,\n                    cmd=self._sandboxed_command,\n                    output=result.stdout,\n                    stderr=result.stderr,\n                )\n            return result\n        finally:\n            if self._switcheroo is not None:\n                self._switcheroo.cleanup()\n\n    def run(self) -> subprocess.CompletedProcess:\n        \"\"\"\n        Set up and run the sandbox in a separate process.\n\n        :return: A `CompletedProcess` object representing the return code and stdout/stderr of the code interpreter.\n        :raises FixableException: If an issue occurs but that can be fixed by the user.\n        :raises Sandbox.SandboxRuntimeException: If the sandbox failed to start or behaved incorrectly regardless of the code being evaluated.\n        :raises Sandbox.ExecutionTimeoutError: If the code interpreter ran for longer than configured.\n        :raises Sandbox.InterruptedExecutionError: If the code interpreter died without providing a return code; usually due to running over resource limits.\n        :raises sandbox.CodeExecutionError: If the code interpreter failed to execute the given code. This does not represent a sandbox failure.\n        \"\"\"\n        reexec_path = os.path.join(self._tmp_dir, \"self.py\")\n        with open(reexec_path, \"w\") as reexec_f:\n            reexec_f.write(self._SelfFile.contents())\n        new_env = os.environ.copy()\n        new_env[self._MARKER_ENVIRONMENT_VARIABLE] = \"1\"\n        data = json.dumps({\"settings\": self._settings})\n        try:\n            result = subprocess.run(\n                (sys.executable, reexec_path),\n                env=new_env,\n                input=data,\n                text=True,\n                capture_output=True,\n                check=True,\n            )\n        except subprocess.CalledProcessError as e:\n            raise self.SandboxRuntimeException(f\"{e} (stderr: {e.stderr})\")\n        else:\n            if not result.stdout:\n                raise self.SandboxRuntimeException(\n                    f\"Subprocess interpreter did not produce any output (stderr: {result.stderr})\"\n                )\n            try:\n                output = json.loads(result.stdout)\n            except json.decoder.JSONDecodeError as e:\n                raise self.SandboxRuntimeException(\n                    f\"Subprocess interpreter produced invalid JSON (stdout: {result.stdout}): {e}\"\n                )\n            if \"exception\" in output:\n                class_name = output[\"exception\"][\"name\"]\n                found_class = None\n                for ex_class in (\n                    self.PlatformNotSupportedException,\n                    self.SandboxRuntimeException,\n                    self.CodeExecutionError,\n                    self.ExecutionTimeoutError,\n                    self.InterruptedExecutionError,\n                    self.GVisorNotInstalledException,\n                    self.CorruptDownloadException,\n                    self.EnvironmentNeedsSetupException,\n                    self.ExecutionError,\n                    self.SandboxException,\n                ):\n                    if ex_class.__name__ == class_name:\n                        found_class = ex_class\n                        break\n                if found_class is None:\n                    exception_str = output[\"exception\"][\"str\"]\n                    raise self.SandboxException(f\"{class_name}: {exception_str}\")\n                raise found_class(\n                    *output[\"exception\"][\"args\"], **output[\"exception\"][\"kwargs\"]\n                )\n            if \"result\" not in output:\n                raise self.SandboxException(\n                    f\"Invalid response from subprocess: {output}\"\n                )\n            return subprocess.CompletedProcess(\n                args=output[\"result\"][\"args\"],\n                returncode=output[\"result\"][\"returncode\"],\n                stdout=base64.b64decode(output[\"result\"][\"stdout\"]).decode(\n                    \"utf-8\", errors=\"replace\"\n                ),\n                stderr=base64.b64decode(output[\"result\"][\"stderr\"]).decode(\n                    \"utf-8\", errors=\"replace\"\n                ),\n            )\n\n    def debug_logs(self, write_fn: typing.Callable[[str, str], typing.Any]):\n        \"\"\"\n        Write debug logs and other system information to the given function.\n\n        May only be called after `run` returns, but may be called even when\n        `run` fails.\n\n        :param write_fn: A function that takes (filename, log line) as arguments.\n        \"\"\"\n        log_paths = []\n        all_logs = []\n        if os.path.isdir(self._logs_path):\n            for log_filename in sorted(os.listdir(self._logs_path)):\n                if not log_filename.endswith(\".txt\"):\n                    continue\n                log_paths.append(os.path.join(self._logs_path, log_filename))\n        else:\n            all_logs.append(\n                (\n                    \"[meta]\",\n                    f\"Logs path {self._logs_path} does not exist or is not a directory.\",\n                )\n            )\n        log_paths.extend(self._EXTRA_DEBUG_LOG_PATHS)\n        runsc_filenames = set()\n        for log_path in log_paths:\n            log_filename = os.path.basename(log_path)\n            if log_filename.startswith(\"runsc.log.\") and log_filename.endswith(\".txt\"):\n                log_filename = \"runsc.\" + self._LOG_FILENAME_TRUNCATE_RE.sub(\n                    \"\", log_filename\n                ).removesuffix(\".txt\")\n                if log_filename in runsc_filenames:\n                    runsc_filename_suffix = 2\n                    while f\"{log_filename}.{runsc_filename_suffix}\" in runsc_filenames:\n                        runsc_filename_suffix += 1\n                    log_filename = f\"{log_filename}.{runsc_filename_suffix}\"\n                runsc_filenames.add(log_filename)\n            try:\n                with open(log_path, \"rb\") as log_f:\n                    for log_line in log_f:\n                        log_line = log_line.replace(b\"\\x00\", b\"\\n\").rstrip()\n                        if not log_line:\n                            continue\n                        for line in log_line.split(b\"\\n\"):\n                            all_logs.append(\n                                (log_filename, line.decode(\"utf-8\", errors=\"replace\"))\n                            )\n            except Exception as e:\n                all_logs.append((log_filename, f\"Failed to open: {e}\"))\n        for cmd in self._EXTRA_DEBUG_LOG_COMMANDS:\n            cmd_str = \"`\" + \" \".join(cmd) + \"`\"\n            try:\n                result = subprocess.run(cmd, capture_output=True, timeout=1, check=True)\n            except subprocess.CalledProcessError as e:\n                all_logs.append(\n                    (cmd_str, f\"Failed: {e} (stdout={e.stdout}, stderr={e.stderr})\")\n                )\n            except Exception as e:\n                all_logs.append((cmd_str, f\"Failed: {e}\"))\n            else:\n                for line in result.stdout.replace(b\"\\x00\", b\"\\n\").split(b\"\\n\"):\n                    line = line.rstrip()\n                    if not line:\n                        continue\n                    all_logs.append((cmd_str, line.decode(\"utf-8\", errors=\"replace\")))\n        for filename, log_entry in all_logs:\n            write_fn(filename, log_entry)\n\n\nSandbox.main()\n\n\nclass UpdateCheck:\n    \"\"\"\n    Check for updates.\n    \"\"\"\n\n    RELEASES_URL = \"https://github.com/EtiennePerot/safe-code-execution/releases.atom\"\n    USER_URL = \"https://github.com/EtiennePerot/safe-code-execution/\"\n    ENABLED = True\n    SELF_VERSION = None\n    LAST_UPDATE_CHECK = None\n    LAST_UPDATE_CACHE = None\n    UPDATE_CHECK_INTERVAL = datetime.timedelta(days=3)\n    VERSION_REGEX = re.compile(r\"<title>\\s*(v?\\d+(?:\\.\\d+)+)\\s*</title>\")\n\n    class VersionCheckError(Exception):\n        pass\n\n    @staticmethod\n    def _parse_version(version_str):\n        return tuple(int(c) for c in version_str.strip().removeprefix(\"v\").split(\".\"))\n\n    @staticmethod\n    def _format_version(version):\n        return \"v\" + \".\".join(str(c) for c in version)\n\n    @staticmethod\n    def _compare(version_a, version_b):\n        \"\"\"\n        Returns -1 if version_a < version_b, 0 if equal, 1 if greater.\n        \"\"\"\n        for a, b in zip(version_a, version_b):\n            if a < b:\n                return -1\n            if a > b:\n                return 1\n        return len\n\n    @classmethod\n    def disable(cls):\n        cls.ENABLED = False\n\n    @classmethod\n    def init_from_frontmatter(cls, file_with_frontmatter):\n        if not cls.ENABLED:\n            return\n        with open(file_with_frontmatter, \"rb\") as f:\n            contents = f.read().decode(\"ascii\").strip()\n        if not contents.startswith('\"\"\"'):\n            raise cls.VersionCheckError(\n                f\"Malformed file contents: {contents[:min(8, len(contents))]}[...]\"\n            )\n        contents = contents[len('\"\"\"') :].strip()\n        version = None\n        for line in contents.split(\"\\n\"):\n            line = line.strip()\n            if line == '\"\"\"':\n                break\n            if line.startswith(\"version:\"):\n                if version is not None:\n                    raise cls.VersionCheckError(\n                        f\"Multiple 'version' lines found: {version} and {line}\"\n                    )\n                version = line[len(\"version:\") :].strip()\n        if version is None:\n            raise cls.VersionCheckError(\"Version metadata not found\")\n        cls.SELF_VERSION = cls._parse_version(version)\n\n    @classmethod\n    def _get_current_version(cls):\n        assert (\n            cls.SELF_VERSION is not None\n        ), \"UpdateCheck.init_from_frontmatter must be called first.\"\n        return cls.SELF_VERSION\n\n    @classmethod\n    def need_check(cls):\n        if cls.LAST_UPDATE_CHECK is None:\n            return True\n        return (\n            datetime.datetime.now() - cls.LAST_UPDATE_CHECK >= cls.UPDATE_CHECK_INTERVAL\n        )\n\n    @classmethod\n    def _get_latest_version(cls):\n        if not cls.need_check():\n            if type(cls.LAST_UPDATE_CACHE) is type(()):\n                return cls.LAST_UPDATE_CACHE\n            raise cls.LAST_UPDATE_CACHE\n        try:\n            try:\n                releases_xml = urllib.request.urlopen(url=cls.RELEASES_URL).read()\n            except urllib.error.HTTPError as e:\n                cls.LAST_UPDATE_CACHE = cls.VersionCheckError(\n                    f\"Failed to retrieve latest version: {e} (URL: {cls.RELEASES_URL})\"\n                )\n                raise cls.LAST_UPDATE_CACHE\n            latest_version = None\n            for match in cls.VERSION_REGEX.finditer(releases_xml.decode(\"utf-8\")):\n                version = cls._parse_version(match.group(1))\n                if latest_version is None or cls._compare(version, latest_version) == 1:\n                    latest_version = version\n            if latest_version is None:\n                cls.LAST_UPDATE_CACHE = cls.VersionCheckError(\n                    f\"Failed to retrieve latest version: no release found (URL: {cls.RELEASES_URL})\"\n                )\n                raise cls.LAST_UPDATE_CACHE\n            cls.LAST_UPDATE_CACHE = latest_version\n            return latest_version\n        finally:\n            cls.LAST_UPDATE_CHECK = datetime.datetime.now()\n\n    @classmethod\n    def get_newer_version(cls) -> typing.Optional[str]:\n        \"\"\"\n        Check for the latest version and return it if newer than current.\n\n        :raises VersionCheckError: If there was an error checking for version.\n        :return: The latest version number if newer than current, else None.\n        \"\"\"\n        if not cls.ENABLED:\n            return None\n        try:\n            current_version = cls._get_current_version()\n        except cls.VersionCheckError as e:\n            raise e.__class__(f\"Checking current version: {e}\")\n        try:\n            latest_version = cls._get_latest_version()\n        except cls.VersionCheckError as e:\n            raise e.__class__(f\"Checking latest version: {e}\")\n        if cls._compare(current_version, latest_version) == -1:\n            return cls._format_version(latest_version)\n        return None\n\n\nUpdateCheck.init_from_frontmatter(os.path.abspath(__file__))\n\n\n_SAMPLE_BASH_INSTRUCTIONS = (\n    \"echo 'Hello from the sandbox!'\",\n    \"date\",\n    \"dmesg\",\n    \"echo 'Bye from the sandbox!'\",\n)\n\n_SAMPLE_PYTHON_INSTRUCTIONS = (\n    \"print('Hello from the sandbox!')\",\n    \"import datetime, sys\",\n    \"print('Current date and time:', datetime.datetime.now())\",\n    \"sys.stdout.flush()\",\n    \"import shutil, subprocess\",\n    \"subprocess.run([shutil.which('dmesg')], check=True)\",\n    \"print('Bye from the sandbox!')\",\n)\n\n\ndef _do_self_tests(debug):\n    _self_tests = (\n        {\n            \"name\": \"simple_python\",\n            \"language\": \"python\",\n            \"code\": _SAMPLE_PYTHON_INSTRUCTIONS,\n            \"debug\": True,\n            \"status\": \"OK\",\n        },\n        {\n            \"name\": \"simple_bash\",\n            \"language\": \"bash\",\n            \"code\": _SAMPLE_BASH_INSTRUCTIONS,\n            \"debug\": True,\n            \"status\": \"OK\",\n        },\n        {\n            \"name\": \"bad_syntax_python\",\n            \"language\": \"python\",\n            \"code\": (\"print('foo\",),\n            \"debug\": True,\n            \"status\": \"ERROR\",\n        },\n        {\n            \"name\": \"bad_syntax_bash\",\n            \"language\": \"bash\",\n            \"code\": (\"echo 'foo\",),\n            \"debug\": True,\n            \"status\": \"ERROR\",\n        },\n        {\n            \"name\": \"long_running_code\",\n            \"language\": \"python\",\n            \"code\": (\n                \"import time\",\n                \"time.sleep(15)\",\n                \"print('Managed to sleep for 15 seconds.')\",\n            ),\n            \"valves\": {\n                \"MAX_RUNTIME_SECONDS\": 5,\n            },\n            \"status\": \"TIMEOUT\",\n        },\n        {\n            \"name\": \"ram_hog\",\n            \"language\": \"python\",\n            \"code\": (\n                \"import time\",\n                \"f = open('/dev/urandom', 'rb')\",\n                \"s = []\",\n                \"for i in range(256): s.append(f.read(1024 * 1024))\",\n                \"time.sleep(1)\",\n                \"print('\\\\n'.join(line for line in open('/proc/self/status').read().split('\\\\n') if line.startswith('Vm')))\",\n                \"print('Managed to hog', len(s), 'megabytes.')\",\n            ),\n            \"valves\": {\n                \"MAX_RAM_MEGABYTES\": 128,\n            },\n            \"status\": \"INTERRUPTED\",\n        },\n    )\n\n    def _print_output(obj):\n        if obj.stdout:\n            print(\"  \\U0001f5e8 Output:\", file=sys.stderr)\n            for stdout_line in obj.stdout.split(\"\\n\"):\n                print(f\"    {stdout_line}\")\n        if obj.stderr:\n            print(\"  \\U0001f41e Debug:\", file=sys.stderr)\n            for stderr_line in obj.stderr.split(\"\\n\"):\n                print(f\"    {stderr_line}\")\n\n    success = True\n    for self_test in _self_tests:\n        name = self_test[\"name\"]\n        language = self_test[\"language\"]\n        code = \"\\n\".join(self_test[\"code\"]) + \"\\n\"\n        want_status = self_test[\"status\"]\n        valves = self_test.get(\"valves\", {})\n        test_env = os.environ.copy()\n        for valve_name, valve_value in valves.items():\n            test_env[\n                _Tools.Valves()._VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX\n                + valve_name\n            ] = str(valve_value)\n        test_argv = [\n            sys.executable,\n            os.path.abspath(__file__),\n            f\"--language={language}\",\n        ]\n        if debug or self_test.get(\"debug\", False):\n            test_argv.append(\"--debug\")\n        print(f\"\\u23f3 Running self-test: {name}\", file=sys.stderr)\n        try:\n            result = subprocess.run(\n                test_argv,\n                env=test_env,\n                input=code,\n                text=True,\n                capture_output=True,\n                timeout=20,\n                check=True,\n            )\n        except subprocess.CalledProcessError as e:\n            success = False\n            _print_output(e)\n            print(\n                f\"\\u274c Self-test {name} failed: process failed: {e}\", file=sys.stderr\n            )\n        except Exception as e:\n            success = False\n            exception_class = e.__class__\n            print(\n                f\"\\u274c Self-test {name} failed: {exception_class}: {e}\",\n                file=sys.stderr,\n            )\n        else:\n            try:\n                result_data = json.loads(result.stdout)\n            except json.decoder.JSONDecodeError as e:\n                _print_output(result)\n                success = False\n                print(\n                    f\"\\u274c Self-test {name} failed: JSON decoding failed: {e}\",\n                    file=sys.stderr,\n                )\n            else:\n                got_status = result_data[\"status\"]\n                if got_status != want_status:\n                    _print_output(result)\n                    success = False\n                    print(\n                        f\"\\u274c Self-test {name} failed: status was {got_status}, expected {want_status}\",\n                        file=sys.stderr,\n                    )\n                else:\n                    if debug:\n                        _print_output(result)\n                    print(f\"\\u2714 Self-test {name} passed.\", file=sys.stderr)\n    if success:\n        print(\"\\u2705 All tool self-tests passed, good go to!\", file=sys.stderr)\n        sys.exit(0)\n    else:\n        print(\"\\u2620 One or more tool self-tests failed.\", file=sys.stderr)\n        sys.exit(1)\n    assert False, \"Unreachable\"\n\n\n# Debug utility: Run code from stdin if running as a normal Python script.\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description=\"Run arbitrary code in a gVisor sandbox.\"\n    )\n    parser.add_argument(\n        \"--language\",\n        choices=(\"python\", \"bash\"),\n        default=\"python\",\n        help=\"Language of the code to run.\",\n    )\n    parser.add_argument(\n        \"--use_sample_code\",\n        action=\"store_true\",\n        default=False,\n        help=\"Run sample code for the given language; otherwise, read code from stdin.\",\n    )\n    parser.add_argument(\n        \"--self_test\",\n        action=\"store_true\",\n        default=False,\n        help=\"Run series of self-tests.\",\n    )\n    parser.add_argument(\n        \"--debug\", action=\"store_true\", default=False, help=\"Enable debug mode.\"\n    )\n    parser.add_argument(\n        \"--want_status\",\n        type=str,\n        default=\"\",\n        help=\"If set, verify that the code evaluation status matches this or exit with error code.\",\n    )\n    args = parser.parse_args()\n\n    if args.debug:\n        os.environ[\n            _Tools.Valves()._VALVE_OVERRIDE_ENVIRONMENT_VARIABLE_NAME_PREFIX + \"DEBUG\"\n        ] = \"true\"\n\n    if args.self_test:\n        _do_self_tests(args.debug)\n\n    if args.use_sample_code:\n        if args.language == \"bash\":\n            code = \"\\n\".join(_SAMPLE_BASH_INSTRUCTIONS) + \"\\n\"\n        else:\n            code = \"\\n\".join(_SAMPLE_PYTHON_INSTRUCTIONS) + \"\\n\"\n    else:\n        code = sys.stdin.read()\n\n    async def _local_run():\n        def _dummy_emitter(event):\n            if not args.want_status:\n                print(f\"Event: {event}\", file=sys.stderr)\n\n        tools = Tools()\n        if args.language == \"bash\":\n            output_str = await tools.run_bash_command(\n                bash_command=code, __event_emitter__=_dummy_emitter\n            )\n        else:\n            output_str = await tools.run_python_code(\n                python_code=code, __event_emitter__=_dummy_emitter\n            )\n        if args.want_status:\n            output = json.loads(output_str)\n            got_status = output[\"status\"]\n            if got_status != args.want_status:\n                raise RuntimeError(\n                    f\"Code evaluation status is {got_status} but expected {args.want_status}\"\n                )\n            print(\n                f\"\\u2705 Code evaluation status is {got_status} as expected.\",\n                file=sys.stderr,\n            )\n        else:\n            print(output_str)\n\n    asyncio.run(_local_run())\n"},"downloads":4424,"upvotes":0,"downvotes":0,"updatedAt":1727943170,"createdAt":1724648982,"user":{"id":"42367af0-87b8-4355-8971-694de25bc23c","username":"etienneperot","name":"","profileImageUrl":"https://www.gravatar.com/avatar/1c6ddc2c21f863a618f80079bb26bb2aed44531847ab5af135c89dcaeb9ad26b?d=mp","createdAt":1723946370}}]