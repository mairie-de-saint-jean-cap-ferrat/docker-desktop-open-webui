[{"id":"6313499e-e04c-41f9-b340-e04789d955b7","userId":"beb784b8-7ac3-40b7-adbb-6eace88c41d5","tool":{"id":"yikes_openrouter","name":"OpenRouter with Dynamic Model Fetching","meta":{"description":"A tool for calling models from OpenRouter and populating the model list.","manifest":{}},"content":"import os\nimport requests\nimport json\nimport time\nfrom typing import List, Union, Generator, Iterator, Optional\nfrom pydantic import BaseModel, Field\nfrom open_webui.utils.misc import pop_system_message\n\nclass ModelInfo(BaseModel):\n    id: str\n    name: str\n    description: Optional[str] = None\n    context_length: Optional[int] = None\n    pricing: Optional[dict] = None\n\nclass Tools:\n    \"\"\"Tools class required by Open-WebUI manifold system\"\"\"\n    def __init__(self):\n        pass\n\nclass Pipe:\n    class Valves(BaseModel):\n        OPENROUTER_API_KEY: str = Field(default=\"\")\n        SITE_URL: str = Field(default=\"\")\n        APP_NAME: str = Field(default=\"\")\n\n    def __init__(self):\n        self.type = \"manifold\"\n        self.id = \"openrouter\"\n        self.name = \"openrouter/\"\n        self.valves = self.Valves(\n            **{\n                \"OPENROUTER_API_KEY\": os.getenv(\"OPENROUTER_API_KEY\", \"\"),\n                \"SITE_URL\": os.getenv(\"SITE_URL\", \"\"),\n                \"APP_NAME\": os.getenv(\"APP_NAME\", \"\")\n            }\n        )\n        self._models_cache = None\n        self._last_fetch_time = 0\n        self._cache_duration = 300  # Cache models for 5 minutes\n\n    def _get_headers(self):\n        return {\n            \"Authorization\": f\"Bearer {self.valves.OPENROUTER_API_KEY}\",\n            \"HTTP-Referer\": self.valves.SITE_URL,\n            \"X-Title\": self.valves.APP_NAME,\n            \"Content-Type\": \"application/json\",\n        }\n\n    def fetch_openrouter_models(self) -> List[dict]:\n        \"\"\"\n        Fetches available models from OpenRouter API.\n        Returns cached results if available and not expired.\n        \"\"\"\n        current_time = time.time()\n        \n        # Return cached models if they're still valid\n        if self._models_cache is not None and (current_time - self._last_fetch_time) < self._cache_duration:\n            return self._models_cache\n\n        try:\n            response = requests.get(\n                \"https://openrouter.ai/api/v1/models\",\n                headers=self._get_headers(),\n                timeout=10\n            )\n            \n            if response.status_code != 200:\n                raise Exception(f\"Failed to fetch models: {response.status_code} - {response.text}\")\n\n            models_data = response.json()\n            \n            # Transform the response into the format expected by Open WebUI\n            processed_models = []\n            for model in models_data.get(\"data\", []):\n                model_info = {\n                    \"id\": model.get(\"id\", \"\"),\n                    \"name\": model.get(\"name\", \"\").split(\"/\")[-1],  # Extract name after last slash\n                    \"description\": model.get(\"description\", \"\"),\n                    \"context_length\": model.get(\"context_length\"),\n                    \"pricing\": {\n                        \"prompt\": model.get(\"pricing\", {}).get(\"prompt\"),\n                        \"completion\": model.get(\"pricing\", {}).get(\"completion\")\n                    }\n                }\n                processed_models.append(model_info)\n\n            # Update cache\n            self._models_cache = processed_models\n            self._last_fetch_time = current_time\n            \n            return processed_models\n\n        except Exception as e:\n            print(f\"Error fetching models: {e}\")\n            # Return cached models if available, even if expired\n            if self._models_cache is not None:\n                return self._models_cache\n            # Return a basic fallback list if everything fails\n            return [\n                {\"id\": \"openai/gpt-3.5-turbo\", \"name\": \"gpt-3.5-turbo\"},\n                {\"id\": \"openai/gpt-4\", \"name\": \"gpt-4\"},\n                {\"id\": \"anthropic/claude-3.5-sonnet\", \"name\": \"claude-3.5-sonnet\"},\n            ]\n\n    def pipes(self) -> List[dict]:\n        \"\"\"Returns the list of available models.\"\"\"\n        return self.fetch_openrouter_models()\n\n    def pipe(self, body: dict) -> Union[str, Generator, Iterator]:\n        system_message, messages = pop_system_message(body[\"messages\"])\n        \n        # Add system message if present\n        if system_message:\n            messages.insert(0, {\"role\": \"system\", \"content\": str(system_message)})\n\n        payload = {\n            \"model\": body[\"model\"],\n            \"messages\": messages,\n            \"max_tokens\": body.get(\"max_tokens\", 4096),\n            \"temperature\": body.get(\"temperature\", 0.8),\n            \"top_p\": body.get(\"top_p\", 0.9),\n            \"stop\": body.get(\"stop\", []),\n            \"stream\": body.get(\"stream\", False)\n        }\n\n        url = \"https://openrouter.ai/api/v1/chat/completions\"\n\n        try:\n            if body.get(\"stream\", False):\n                return self.stream_response(url, self._get_headers(), payload)\n            else:\n                return self.non_stream_response(url, self._get_headers(), payload)\n        except requests.exceptions.RequestException as e:\n            print(f\"Request failed: {e}\")\n            return f\"Error: Request failed: {e}\"\n        except Exception as e:\n            print(f\"Error in pipe method: {e}\")\n            return f\"Error: {e}\"\n\n    def stream_response(self, url, headers, payload):\n        try:\n            with requests.post(\n                url, headers=headers, json=payload, stream=True, timeout=(3.05, 60)\n            ) as response:\n                if response.status_code != 200:\n                    raise Exception(f\"HTTP Error {response.status_code}: {response.text}\")\n\n                for line in response.iter_lines():\n                    if line:\n                        line = line.decode(\"utf-8\")\n                        if line.startswith(\"data: \"):\n                            try:\n                                data = json.loads(line[6:])\n                                if \"choices\" in data and len(data[\"choices\"]) > 0:\n                                    choice = data[\"choices\"][0]\n                                    if \"delta\" in choice and \"content\" in choice[\"delta\"]:\n                                        yield choice[\"delta\"][\"content\"]\n                                    elif \"message\" in choice and \"content\" in choice[\"message\"]:\n                                        yield choice[\"message\"][\"content\"]\n\n                                time.sleep(0.01)  # Small delay to prevent overwhelming the client\n\n                            except json.JSONDecodeError:\n                                print(f\"Failed to parse JSON: {line}\")\n                            except KeyError as e:\n                                print(f\"Unexpected data structure: {e}\")\n                                print(f\"Full data: {data}\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Request failed: {e}\")\n            yield f\"Error: Request failed: {e}\"\n        except Exception as e:\n            print(f\"General error in stream_response method: {e}\")\n            yield f\"Error: {e}\"\n\n    def non_stream_response(self, url, headers, payload):\n        try:\n            response = requests.post(\n                url, headers=headers, json=payload, timeout=(3.05, 60)\n            )\n            if response.status_code != 200:\n                raise Exception(f\"HTTP Error {response.status_code}: {response.text}\")\n\n            res = response.json()\n            return (\n                res[\"choices\"][0][\"message\"][\"content\"]\n                if \"choices\" in res and res[\"choices\"]\n                else \"\"\n            )\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed non-stream request: {e}\")\n            return f\"Error: {e}\""},"downloads":735,"upvotes":0,"downvotes":0,"updatedAt":1729976064,"createdAt":1729975137,"user":{"id":"beb784b8-7ac3-40b7-adbb-6eace88c41d5","username":"yikesawjeez","name":"","profileImageUrl":"https://www.gravatar.com/avatar/4f42bc9e73275dc3d9cfd200dd2de98095d50c525c941a9b3275a36ec7750c67?d=mp","createdAt":1729822314}}]